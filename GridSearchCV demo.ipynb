{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm(y_real, y_pred, t='test'):\n",
    "    cf = confusion_matrix(y_real, y_pred)\n",
    "    print(f\"Confusion Matrix {t}: \")\n",
    "    akws = {\"ha\": 'center',\"va\": 'top'}\n",
    "    sns.heatmap(cf/(np.sum(cf)),annot=True, fmt='0.2%',cmap='Blues', annot_kws=akws, cbar=False)\n",
    "\n",
    "    akws = {\"ha\": 'center',\"va\": 'bottom'}\n",
    "    sns.heatmap(cf,annot=True, fmt='0',cmap='Blues', annot_kws=akws)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('FOREX_eursgd-hour-High.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Bid_Open</th>\n",
       "      <th>Bid_High</th>\n",
       "      <th>Bid_Low</th>\n",
       "      <th>Bid_Close</th>\n",
       "      <th>Bid_Volume</th>\n",
       "      <th>Ask_Open</th>\n",
       "      <th>Ask_High</th>\n",
       "      <th>Ask_Low</th>\n",
       "      <th>Ask_Close</th>\n",
       "      <th>Ask_Volume</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'2012-01-01T23:00:00'</td>\n",
       "      <td>1.67740</td>\n",
       "      <td>1.67891</td>\n",
       "      <td>1.67550</td>\n",
       "      <td>1.67835</td>\n",
       "      <td>1647.9100</td>\n",
       "      <td>1.67830</td>\n",
       "      <td>1.68018</td>\n",
       "      <td>1.67628</td>\n",
       "      <td>1.67905</td>\n",
       "      <td>1656.54</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'2012-01-02T00:00:00'</td>\n",
       "      <td>1.67894</td>\n",
       "      <td>1.68058</td>\n",
       "      <td>1.67687</td>\n",
       "      <td>1.67903</td>\n",
       "      <td>1029.3199</td>\n",
       "      <td>1.67966</td>\n",
       "      <td>1.68453</td>\n",
       "      <td>1.67895</td>\n",
       "      <td>1.68001</td>\n",
       "      <td>1034.25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'2012-01-02T01:00:00'</td>\n",
       "      <td>1.67897</td>\n",
       "      <td>1.68036</td>\n",
       "      <td>1.67605</td>\n",
       "      <td>1.67631</td>\n",
       "      <td>1307.1200</td>\n",
       "      <td>1.67983</td>\n",
       "      <td>1.68342</td>\n",
       "      <td>1.67720</td>\n",
       "      <td>1.67809</td>\n",
       "      <td>1321.67</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'2012-01-02T02:00:00'</td>\n",
       "      <td>1.67667</td>\n",
       "      <td>1.67831</td>\n",
       "      <td>1.67551</td>\n",
       "      <td>1.67728</td>\n",
       "      <td>401.2100</td>\n",
       "      <td>1.67839</td>\n",
       "      <td>1.67959</td>\n",
       "      <td>1.67736</td>\n",
       "      <td>1.67900</td>\n",
       "      <td>412.30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'2012-01-02T03:00:00'</td>\n",
       "      <td>1.67737</td>\n",
       "      <td>1.67793</td>\n",
       "      <td>1.67543</td>\n",
       "      <td>1.67688</td>\n",
       "      <td>438.8700</td>\n",
       "      <td>1.67892</td>\n",
       "      <td>1.67933</td>\n",
       "      <td>1.67694</td>\n",
       "      <td>1.67787</td>\n",
       "      <td>452.91</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Timestamp  Bid_Open  Bid_High  Bid_Low  Bid_Close  Bid_Volume  \\\n",
       "0  '2012-01-01T23:00:00'   1.67740   1.67891  1.67550    1.67835   1647.9100   \n",
       "1  '2012-01-02T00:00:00'   1.67894   1.68058  1.67687    1.67903   1029.3199   \n",
       "2  '2012-01-02T01:00:00'   1.67897   1.68036  1.67605    1.67631   1307.1200   \n",
       "3  '2012-01-02T02:00:00'   1.67667   1.67831  1.67551    1.67728    401.2100   \n",
       "4  '2012-01-02T03:00:00'   1.67737   1.67793  1.67543    1.67688    438.8700   \n",
       "\n",
       "   Ask_Open  Ask_High  Ask_Low  Ask_Close  Ask_Volume  Class  \n",
       "0   1.67830   1.68018  1.67628    1.67905     1656.54   True  \n",
       "1   1.67966   1.68453  1.67895    1.68001     1034.25  False  \n",
       "2   1.67983   1.68342  1.67720    1.67809     1321.67  False  \n",
       "3   1.67839   1.67959  1.67736    1.67900      412.30  False  \n",
       "4   1.67892   1.67933  1.67694    1.67787      452.91   True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43825 entries, 0 to 43824\n",
      "Data columns (total 12 columns):\n",
      "Timestamp     43825 non-null object\n",
      "Bid_Open      43825 non-null float64\n",
      "Bid_High      43825 non-null float64\n",
      "Bid_Low       43825 non-null float64\n",
      "Bid_Close     43825 non-null float64\n",
      "Bid_Volume    43825 non-null float64\n",
      "Ask_Open      43825 non-null float64\n",
      "Ask_High      43825 non-null float64\n",
      "Ask_Low       43825 non-null float64\n",
      "Ask_Close     43825 non-null float64\n",
      "Ask_Volume    43825 non-null float64\n",
      "Class         43825 non-null bool\n",
      "dtypes: bool(1), float64(10), object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bid_Open</th>\n",
       "      <th>Bid_High</th>\n",
       "      <th>Bid_Low</th>\n",
       "      <th>Bid_Close</th>\n",
       "      <th>Bid_Volume</th>\n",
       "      <th>Ask_Open</th>\n",
       "      <th>Ask_High</th>\n",
       "      <th>Ask_Low</th>\n",
       "      <th>Ask_Close</th>\n",
       "      <th>Ask_Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43825.000000</td>\n",
       "      <td>43825.000000</td>\n",
       "      <td>43825.000000</td>\n",
       "      <td>43825.000000</td>\n",
       "      <td>43825.000000</td>\n",
       "      <td>43825.000000</td>\n",
       "      <td>43825.000000</td>\n",
       "      <td>43825.000000</td>\n",
       "      <td>43825.000000</td>\n",
       "      <td>43825.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.593487</td>\n",
       "      <td>1.594566</td>\n",
       "      <td>1.592425</td>\n",
       "      <td>1.593496</td>\n",
       "      <td>4020.047106</td>\n",
       "      <td>1.594046</td>\n",
       "      <td>1.595146</td>\n",
       "      <td>1.592995</td>\n",
       "      <td>1.594041</td>\n",
       "      <td>4015.054009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.068808</td>\n",
       "      <td>0.068727</td>\n",
       "      <td>0.068885</td>\n",
       "      <td>0.068806</td>\n",
       "      <td>2819.768895</td>\n",
       "      <td>0.068767</td>\n",
       "      <td>0.068686</td>\n",
       "      <td>0.068842</td>\n",
       "      <td>0.068767</td>\n",
       "      <td>2814.871001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.436680</td>\n",
       "      <td>1.438870</td>\n",
       "      <td>1.435360</td>\n",
       "      <td>1.436780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.437200</td>\n",
       "      <td>1.439260</td>\n",
       "      <td>1.435820</td>\n",
       "      <td>1.437270</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.536610</td>\n",
       "      <td>1.537780</td>\n",
       "      <td>1.535520</td>\n",
       "      <td>1.536630</td>\n",
       "      <td>1914.610000</td>\n",
       "      <td>1.537280</td>\n",
       "      <td>1.538390</td>\n",
       "      <td>1.536130</td>\n",
       "      <td>1.537260</td>\n",
       "      <td>1919.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.592250</td>\n",
       "      <td>1.593160</td>\n",
       "      <td>1.591310</td>\n",
       "      <td>1.592270</td>\n",
       "      <td>3349.770000</td>\n",
       "      <td>1.592750</td>\n",
       "      <td>1.593650</td>\n",
       "      <td>1.591800</td>\n",
       "      <td>1.592760</td>\n",
       "      <td>3361.129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.633760</td>\n",
       "      <td>1.634900</td>\n",
       "      <td>1.632610</td>\n",
       "      <td>1.633760</td>\n",
       "      <td>5475.569800</td>\n",
       "      <td>1.634260</td>\n",
       "      <td>1.635430</td>\n",
       "      <td>1.633150</td>\n",
       "      <td>1.634250</td>\n",
       "      <td>5479.470200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.767000</td>\n",
       "      <td>1.767070</td>\n",
       "      <td>1.764670</td>\n",
       "      <td>1.767070</td>\n",
       "      <td>30587.439500</td>\n",
       "      <td>1.767230</td>\n",
       "      <td>1.767280</td>\n",
       "      <td>1.764920</td>\n",
       "      <td>1.767280</td>\n",
       "      <td>30019.269500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Bid_Open      Bid_High       Bid_Low     Bid_Close    Bid_Volume  \\\n",
       "count  43825.000000  43825.000000  43825.000000  43825.000000  43825.000000   \n",
       "mean       1.593487      1.594566      1.592425      1.593496   4020.047106   \n",
       "std        0.068808      0.068727      0.068885      0.068806   2819.768895   \n",
       "min        1.436680      1.438870      1.435360      1.436780      0.000000   \n",
       "25%        1.536610      1.537780      1.535520      1.536630   1914.610000   \n",
       "50%        1.592250      1.593160      1.591310      1.592270   3349.770000   \n",
       "75%        1.633760      1.634900      1.632610      1.633760   5475.569800   \n",
       "max        1.767000      1.767070      1.764670      1.767070  30587.439500   \n",
       "\n",
       "           Ask_Open      Ask_High       Ask_Low     Ask_Close    Ask_Volume  \n",
       "count  43825.000000  43825.000000  43825.000000  43825.000000  43825.000000  \n",
       "mean       1.594046      1.595146      1.592995      1.594041   4015.054009  \n",
       "std        0.068767      0.068686      0.068842      0.068767   2814.871001  \n",
       "min        1.437200      1.439260      1.435820      1.437270      0.000000  \n",
       "25%        1.537280      1.538390      1.536130      1.537260   1919.020000  \n",
       "50%        1.592750      1.593650      1.591800      1.592760   3361.129900  \n",
       "75%        1.634260      1.635430      1.633150      1.634250   5479.470200  \n",
       "max        1.767230      1.767280      1.764920      1.767280  30019.269500  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change the target to 1 and 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'] = lb.fit_transform(df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Bid_Open</th>\n",
       "      <th>Bid_High</th>\n",
       "      <th>Bid_Low</th>\n",
       "      <th>Bid_Close</th>\n",
       "      <th>Bid_Volume</th>\n",
       "      <th>Ask_Open</th>\n",
       "      <th>Ask_High</th>\n",
       "      <th>Ask_Low</th>\n",
       "      <th>Ask_Close</th>\n",
       "      <th>Ask_Volume</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'2012-01-01T23:00:00'</td>\n",
       "      <td>1.67740</td>\n",
       "      <td>1.67891</td>\n",
       "      <td>1.67550</td>\n",
       "      <td>1.67835</td>\n",
       "      <td>1647.9100</td>\n",
       "      <td>1.67830</td>\n",
       "      <td>1.68018</td>\n",
       "      <td>1.67628</td>\n",
       "      <td>1.67905</td>\n",
       "      <td>1656.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'2012-01-02T00:00:00'</td>\n",
       "      <td>1.67894</td>\n",
       "      <td>1.68058</td>\n",
       "      <td>1.67687</td>\n",
       "      <td>1.67903</td>\n",
       "      <td>1029.3199</td>\n",
       "      <td>1.67966</td>\n",
       "      <td>1.68453</td>\n",
       "      <td>1.67895</td>\n",
       "      <td>1.68001</td>\n",
       "      <td>1034.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'2012-01-02T01:00:00'</td>\n",
       "      <td>1.67897</td>\n",
       "      <td>1.68036</td>\n",
       "      <td>1.67605</td>\n",
       "      <td>1.67631</td>\n",
       "      <td>1307.1200</td>\n",
       "      <td>1.67983</td>\n",
       "      <td>1.68342</td>\n",
       "      <td>1.67720</td>\n",
       "      <td>1.67809</td>\n",
       "      <td>1321.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'2012-01-02T02:00:00'</td>\n",
       "      <td>1.67667</td>\n",
       "      <td>1.67831</td>\n",
       "      <td>1.67551</td>\n",
       "      <td>1.67728</td>\n",
       "      <td>401.2100</td>\n",
       "      <td>1.67839</td>\n",
       "      <td>1.67959</td>\n",
       "      <td>1.67736</td>\n",
       "      <td>1.67900</td>\n",
       "      <td>412.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'2012-01-02T03:00:00'</td>\n",
       "      <td>1.67737</td>\n",
       "      <td>1.67793</td>\n",
       "      <td>1.67543</td>\n",
       "      <td>1.67688</td>\n",
       "      <td>438.8700</td>\n",
       "      <td>1.67892</td>\n",
       "      <td>1.67933</td>\n",
       "      <td>1.67694</td>\n",
       "      <td>1.67787</td>\n",
       "      <td>452.91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Timestamp  Bid_Open  Bid_High  Bid_Low  Bid_Close  Bid_Volume  \\\n",
       "0  '2012-01-01T23:00:00'   1.67740   1.67891  1.67550    1.67835   1647.9100   \n",
       "1  '2012-01-02T00:00:00'   1.67894   1.68058  1.67687    1.67903   1029.3199   \n",
       "2  '2012-01-02T01:00:00'   1.67897   1.68036  1.67605    1.67631   1307.1200   \n",
       "3  '2012-01-02T02:00:00'   1.67667   1.67831  1.67551    1.67728    401.2100   \n",
       "4  '2012-01-02T03:00:00'   1.67737   1.67793  1.67543    1.67688    438.8700   \n",
       "\n",
       "   Ask_Open  Ask_High  Ask_Low  Ask_Close  Ask_Volume  Class  \n",
       "0   1.67830   1.68018  1.67628    1.67905     1656.54      1  \n",
       "1   1.67966   1.68453  1.67895    1.68001     1034.25      0  \n",
       "2   1.67983   1.68342  1.67720    1.67809     1321.67      0  \n",
       "3   1.67839   1.67959  1.67736    1.67900      412.30      0  \n",
       "4   1.67892   1.67933  1.67694    1.67787      452.91      1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Class', 'Timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a baseline random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix test: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      4545\n",
      "           1       0.61      0.61      0.61      4220\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      8765\n",
      "   macro avg       0.63      0.63      0.63      8765\n",
      "weighted avg       0.63      0.63      0.63      8765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not getting great accuracy from this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:   55.8s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1920 out of 1920 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [10, 50, 100], 'criterion': ['gini', 'entropy'], 'max_depth': [1, 2, 5, 10], 'min_samples_leaf': [10, 15, 20, 25], 'min_impurity_decrease': [0.001, 0.01, 0.1, 0.15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10,50,100],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [1, 2, 5, 10],\n",
    "    \"min_samples_leaf\": [10, 15, 20, 25],\n",
    "    \"min_impurity_decrease\": [.001, .01, .1, .15]\n",
    "}\n",
    "gs_tree = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy',  n_jobs=-1, verbose=2)\n",
    "gs_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 5,\n",
       " 'min_impurity_decrease': 0.001,\n",
       " 'min_samples_leaf': 25,\n",
       " 'n_estimators': 10}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(criterion='gini', max_depth=5, min_impurity_decrease=.001, min_samples_leaf=25, n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.001, min_impurity_split=None,\n",
       "            min_samples_leaf=25, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = rf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix test: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm(y_test, preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.41      0.48      4545\n",
      "           1       0.51      0.65      0.57      4220\n",
      "\n",
      "   micro avg       0.53      0.53      0.53      8765\n",
      "   macro avg       0.53      0.53      0.52      8765\n",
      "weighted avg       0.53      0.53      0.52      8765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously terrible, let us look at a better way to checkout the results of the gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.16500635, 0.74180112, 1.54619808, 0.16199794, 0.83760009,\n",
       "        1.68319845, 0.17259936, 0.88840127, 1.65979447, 0.1730032 ,\n",
       "        0.80399919, 1.61579885, 0.17100019, 0.8435977 , 1.75039334,\n",
       "        0.17379823, 0.84259439, 1.59919443, 0.17059722, 0.81339464,\n",
       "        1.70019674, 0.17799845, 0.99199762, 2.02299843, 0.23900051,\n",
       "        0.96379876, 1.9451983 , 0.20219836, 0.97300348, 1.87520037,\n",
       "        0.19799709, 0.95739846, 1.87400155, 0.2013989 , 0.95299649,\n",
       "        1.88719883, 0.19799953, 0.94640031, 1.85539885, 0.19959903,\n",
       "        0.95019698, 1.86939816, 0.20019164, 0.95779777, 1.99879808,\n",
       "        0.22779808, 0.94339886, 1.86079803, 0.27139792, 1.33500209,\n",
       "        2.48779793, 0.27239628, 1.2381988 , 2.49579391, 0.27699418,\n",
       "        1.28801265, 2.47839479, 0.24919853, 1.24739618, 2.5902009 ,\n",
       "        0.1945971 , 0.99859943, 2.00579824, 0.22759924, 0.95320015,\n",
       "        1.8855969 , 0.20099854, 0.95419884, 1.85479426, 0.20339713,\n",
       "        0.96639733, 1.92040148, 0.20399818, 0.98080025, 1.89999633,\n",
       "        0.20679836, 0.93919835, 1.90499835, 0.20680032, 0.95139961,\n",
       "        1.93779674, 0.21260076, 0.99059248, 2.22939515, 0.27620149,\n",
       "        1.03539071, 2.14020061, 0.26359572, 1.04900002, 2.08879786,\n",
       "        0.22159882, 1.11099977, 2.39259777, 0.2699986 , 1.05040483,\n",
       "        2.0928009 , 0.34840078, 1.53619823, 3.04580097, 0.33239827,\n",
       "        1.75399933, 3.05439997, 0.35499406, 1.50019855, 2.78319511,\n",
       "        0.30919862, 1.45739813, 2.86139717, 0.20059795, 0.97939782,\n",
       "        1.92359776, 0.20579867, 0.97499819, 1.9041997 , 0.20719366,\n",
       "        1.01860042, 2.09819932, 0.2243988 , 1.04479861, 1.97379861,\n",
       "        0.21759791, 1.05059862, 2.12359953, 0.25659575, 0.98699985,\n",
       "        1.93779798, 0.20739803, 0.95499802, 1.97319889, 0.20579839,\n",
       "        0.97039781, 1.99880581, 0.21219544, 0.96119623, 1.95240164,\n",
       "        0.20919733, 0.99599938, 2.1665997 , 0.23679633, 0.97979569,\n",
       "        1.93859878, 0.2089982 , 0.95039868, 1.93379755, 0.29499722,\n",
       "        1.41539841, 2.88839836, 0.30159726, 1.41939883, 2.82019744,\n",
       "        0.28599958, 1.36320114, 2.9634006 , 0.29719625, 1.42618961,\n",
       "        2.92819953, 0.20759811, 0.94760017, 1.95639973, 0.2039979 ,\n",
       "        0.98359818, 1.96779804, 0.21219716, 0.98359399, 1.99560122,\n",
       "        0.20739679, 0.96660094, 1.9547998 , 0.2007987 , 0.9594008 ,\n",
       "        1.94819694, 0.20519762, 1.02319751, 2.04839578, 0.24019995,\n",
       "        1.07619286, 1.9538002 , 0.20459495, 0.97460003, 1.92579627,\n",
       "        0.20819855, 0.98179879, 1.92079811, 0.20679688, 0.99319987,\n",
       "        1.93639889, 0.20179658, 0.9786046 , 1.97539954, 0.21699762,\n",
       "        1.00380316, 1.95819731, 0.26639791, 1.30559964, 2.74179878,\n",
       "        0.31199903, 1.27519813, 2.77739825, 0.27019868, 1.3297987 ,\n",
       "        2.57159867, 0.27039948, 1.26859722, 2.5261981 , 0.27220006,\n",
       "        1.29280114, 2.55159864, 0.27619853, 1.28859653, 2.68879647,\n",
       "        0.28959842, 1.303198  , 2.54280076, 0.27199936, 1.27139926,\n",
       "        2.52859707, 0.26679926, 1.26879749, 2.53079104, 0.26439934,\n",
       "        1.30599937, 2.5331964 , 0.26019964, 1.26159811, 2.59499793,\n",
       "        0.25959892, 1.27840028, 2.64919863, 0.29099836, 1.25459871,\n",
       "        2.52720032, 0.27439713, 1.27719731, 2.50379467, 0.26419888,\n",
       "        1.26999869, 2.54739718, 0.26899996, 1.30560074, 2.48679376,\n",
       "        0.37639785, 1.85899887, 3.83099728, 0.44559627, 1.77479739,\n",
       "        3.61859808, 0.39799457, 1.83800316, 3.65499821, 0.37959681,\n",
       "        1.77739825, 3.66379566, 0.26539798, 1.27539854, 2.83120012,\n",
       "        0.30339851, 1.34260011, 2.61379833, 0.27279973, 1.27619929,\n",
       "        2.58259888, 0.2697988 , 1.29719782, 2.57299809, 0.26799898,\n",
       "        1.30179973, 2.54920101, 0.26259966, 1.29639821, 2.63559504,\n",
       "        0.2673964 , 1.44259849, 2.58379626, 0.27599592, 1.30439844,\n",
       "        2.66980038, 0.28339734, 1.32459826, 2.62139721, 0.27100263,\n",
       "        1.26619983, 2.64619904, 0.27640071, 1.28439283, 2.53919878,\n",
       "        0.27499747, 1.36299958, 2.75379939, 0.41779919, 2.19419851,\n",
       "        4.21839919, 0.46279917, 2.09059839, 4.17079396, 0.45319724,\n",
       "        2.00119996, 4.29859838, 0.45179849, 2.1665997 , 4.31639671,\n",
       "        0.26239882, 1.25739875, 2.57959857, 0.27619934, 1.33599863,\n",
       "        2.59179611, 0.29339843, 1.29839869, 2.61779885, 0.27459869,\n",
       "        1.30439849, 2.6443996 , 0.26459908, 1.4039979 , 2.57759738,\n",
       "        0.27559986, 1.27540121, 2.57260008, 0.2651989 , 1.30260844,\n",
       "        2.55859976, 0.26919851, 1.29159985, 2.5267961 , 0.27279763,\n",
       "        1.30020108, 2.53259759, 0.26679816, 1.33779907, 2.80640163,\n",
       "        0.26819658, 1.3042057 , 2.57919674, 0.27559843, 1.29599814,\n",
       "        2.57659798, 0.43899813, 2.11939778, 4.1633997 , 0.4394012 ,\n",
       "        2.13279819, 4.32539797, 0.50979862, 2.20639873, 4.26659746,\n",
       "        0.432797  , 2.01339555, 4.33819976, 0.27399769, 1.24680009,\n",
       "        2.52119789, 0.26739678, 1.29359894, 2.66340036, 0.26879768,\n",
       "        1.3490027 , 2.56919651, 0.27839584, 1.28679557, 2.53160005,\n",
       "        0.27859893, 1.3145999 , 2.52119703, 0.27139869, 1.28279715,\n",
       "        2.58399935, 0.27059894, 1.25880027, 2.53059611, 0.27459903,\n",
       "        1.26459746, 2.84719892, 0.27519894, 1.26579852, 2.58319979,\n",
       "        0.27079902, 1.28699951, 2.61339865, 0.27060013, 1.31379857,\n",
       "        2.56199684, 0.26559839, 1.26579742, 2.29739671]),\n",
       " 'std_fit_time': array([0.01076195, 0.01109046, 0.06109347, 0.00442791, 0.04438041,\n",
       "        0.07732911, 0.00662059, 0.07334047, 0.04366837, 0.0090551 ,\n",
       "        0.02876686, 0.02651441, 0.01045231, 0.07172374, 0.07877187,\n",
       "        0.01147811, 0.04062484, 0.0302817 , 0.0100505 , 0.03733155,\n",
       "        0.03071083, 0.01896264, 0.0629178 , 0.11567398, 0.01920575,\n",
       "        0.01689241, 0.03603579, 0.00725105, 0.0253465 , 0.02491996,\n",
       "        0.01119075, 0.0288058 , 0.02780445, 0.00516273, 0.0093968 ,\n",
       "        0.01747508, 0.00451619, 0.0367666 , 0.02595873, 0.00531589,\n",
       "        0.02286417, 0.03948098, 0.00953551, 0.0327652 , 0.13857349,\n",
       "        0.02049901, 0.02071377, 0.0108688 , 0.00691721, 0.01836479,\n",
       "        0.04709731, 0.02339848, 0.03575765, 0.04269943, 0.02388622,\n",
       "        0.02797462, 0.08277077, 0.02269114, 0.04094525, 0.11924837,\n",
       "        0.00535187, 0.10796262, 0.08228822, 0.0265165 , 0.01504004,\n",
       "        0.06579457, 0.00357688, 0.03059738, 0.01808099, 0.01046101,\n",
       "        0.02828655, 0.08228234, 0.00756319, 0.0405247 , 0.02576025,\n",
       "        0.00444453, 0.01821586, 0.03412909, 0.01230263, 0.0427024 ,\n",
       "        0.05538345, 0.0200642 , 0.0439351 , 0.26888083, 0.04970114,\n",
       "        0.06910284, 0.11579983, 0.02956016, 0.03472278, 0.0474106 ,\n",
       "        0.02692454, 0.0601556 , 0.20567249, 0.06057257, 0.06191145,\n",
       "        0.12297126, 0.0527819 , 0.12329964, 0.12324667, 0.04280361,\n",
       "        0.30027118, 0.24189236, 0.04601787, 0.1207535 , 0.08232301,\n",
       "        0.03645447, 0.06492287, 0.08856075, 0.00659177, 0.0320675 ,\n",
       "        0.02758305, 0.01235136, 0.02489106, 0.02587272, 0.00775184,\n",
       "        0.04893201, 0.1736639 , 0.01520016, 0.09431563, 0.01530384,\n",
       "        0.0098512 , 0.12917432, 0.2230455 , 0.03417231, 0.04109835,\n",
       "        0.03473447, 0.00694557, 0.03595063, 0.02660283, 0.00743932,\n",
       "        0.0251621 , 0.10333118, 0.01690468, 0.01643497, 0.01430431,\n",
       "        0.00483646, 0.03078943, 0.20273094, 0.02781095, 0.03434882,\n",
       "        0.05539838, 0.01511217, 0.01354254, 0.0243841 , 0.0222005 ,\n",
       "        0.05995586, 0.05459975, 0.02589434, 0.06059666, 0.17034051,\n",
       "        0.00712583, 0.04005707, 0.14513849, 0.02777764, 0.06104011,\n",
       "        0.09727379, 0.00861679, 0.01817319, 0.04267359, 0.00841283,\n",
       "        0.03188527, 0.05370352, 0.00773078, 0.02632899, 0.02193453,\n",
       "        0.00665123, 0.01043939, 0.04135028, 0.00688128, 0.01032762,\n",
       "        0.04025782, 0.00292485, 0.06623222, 0.15542434, 0.02580143,\n",
       "        0.09384804, 0.04623818, 0.00265683, 0.01848641, 0.03622364,\n",
       "        0.0135562 , 0.01936363, 0.0440505 , 0.0037614 , 0.04260228,\n",
       "        0.03510879, 0.00416531, 0.01536158, 0.05626638, 0.01029518,\n",
       "        0.03694046, 0.03148048, 0.00781287, 0.02403743, 0.19835528,\n",
       "        0.02938654, 0.05067621, 0.13613988, 0.0099467 , 0.11846734,\n",
       "        0.02919371, 0.00993168, 0.02170378, 0.04366819, 0.01304665,\n",
       "        0.04196701, 0.04853367, 0.01126782, 0.0349138 , 0.19262307,\n",
       "        0.03899509, 0.0793787 , 0.03558678, 0.01189962, 0.03286764,\n",
       "        0.04552097, 0.00741206, 0.0372588 , 0.04934349, 0.00492372,\n",
       "        0.03839186, 0.0367684 , 0.00949533, 0.01281558, 0.0597431 ,\n",
       "        0.00801562, 0.0268943 , 0.12488998, 0.02855236, 0.024824  ,\n",
       "        0.04981996, 0.01139533, 0.01848792, 0.03781173, 0.00577622,\n",
       "        0.05188845, 0.03790911, 0.0191639 , 0.02750596, 0.03127111,\n",
       "        0.03429691, 0.16979679, 0.24063047, 0.07229741, 0.06303937,\n",
       "        0.1016507 , 0.02596641, 0.09335865, 0.07311495, 0.05679012,\n",
       "        0.06671525, 0.17017221, 0.01167121, 0.03505344, 0.16324413,\n",
       "        0.03180251, 0.08046392, 0.04963976, 0.01428876, 0.00783388,\n",
       "        0.0302955 , 0.0128596 , 0.03588862, 0.05119492, 0.00469197,\n",
       "        0.02518303, 0.02674854, 0.00320057, 0.04013151, 0.14768346,\n",
       "        0.00941483, 0.14226029, 0.08883595, 0.00878478, 0.03491979,\n",
       "        0.06980457, 0.01001319, 0.04929281, 0.04412338, 0.01224518,\n",
       "        0.02918364, 0.02999679, 0.00804526, 0.01883034, 0.02906114,\n",
       "        0.01492558, 0.13732482, 0.20189269, 0.04101327, 0.24833675,\n",
       "        0.34340444, 0.03439523, 0.17721963, 0.32174695, 0.04844934,\n",
       "        0.13192318, 0.53731768, 0.09145564, 0.16521336, 0.25011313,\n",
       "        0.00567693, 0.0227559 , 0.06700669, 0.00699708, 0.09054974,\n",
       "        0.13899453, 0.02308771, 0.03827254, 0.05678791, 0.01367607,\n",
       "        0.06240054, 0.16355427, 0.00265338, 0.13444588, 0.07924364,\n",
       "        0.01083522, 0.01399439, 0.06299465, 0.00895311, 0.03412159,\n",
       "        0.03775665, 0.01094369, 0.04080493, 0.05368549, 0.00786109,\n",
       "        0.03173571, 0.04060413, 0.00559942, 0.16068748, 0.20692961,\n",
       "        0.01385125, 0.0299651 , 0.05795073, 0.01526464, 0.03275951,\n",
       "        0.04422465, 0.06883304, 0.08551042, 0.34912357, 0.03370445,\n",
       "        0.19047442, 0.55649255, 0.07728092, 0.15305647, 0.35489944,\n",
       "        0.06098145, 0.04361271, 0.43906932, 0.00792499, 0.02147919,\n",
       "        0.04750368, 0.00700299, 0.0218602 , 0.12248285, 0.00526851,\n",
       "        0.05855946, 0.06665819, 0.00984499, 0.03891362, 0.0254046 ,\n",
       "        0.01125298, 0.06154859, 0.02985005, 0.00567799, 0.01555057,\n",
       "        0.08546674, 0.00945798, 0.02676734, 0.02641639, 0.01074365,\n",
       "        0.03647144, 0.15421426, 0.00679486, 0.03140985, 0.06547339,\n",
       "        0.00556333, 0.04450258, 0.09986204, 0.00796406, 0.05135515,\n",
       "        0.03966203, 0.00241683, 0.01889408, 0.03530716]),\n",
       " 'mean_score_time': array([0.01419353, 0.03160639, 0.05799918, 0.00880051, 0.03080053,\n",
       "        0.0622014 , 0.01019874, 0.03059649, 0.05720143, 0.00759726,\n",
       "        0.03280087, 0.06019964, 0.00779648, 0.02939649, 0.06160765,\n",
       "        0.00820327, 0.03279862, 0.05540113, 0.00800204, 0.03300009,\n",
       "        0.07620368, 0.00880156, 0.03940396, 0.06500282, 0.00939841,\n",
       "        0.03360009, 0.06360149, 0.00919976, 0.03379569, 0.06260004,\n",
       "        0.00959945, 0.03500462, 0.06700649, 0.00900059, 0.0342011 ,\n",
       "        0.06260204, 0.00919871, 0.03360143, 0.06379962, 0.00980053,\n",
       "        0.038802  , 0.07380209, 0.0084003 , 0.04120021, 0.08020072,\n",
       "        0.01220021, 0.0354001 , 0.0632    , 0.00960093, 0.03639712,\n",
       "        0.06940002, 0.00939941, 0.03579965, 0.06840315, 0.00940104,\n",
       "        0.04038525, 0.07320151, 0.00940261, 0.03600602, 0.07899995,\n",
       "        0.00900092, 0.03419719, 0.06400018, 0.01119666, 0.03579903,\n",
       "        0.06540146, 0.01060047, 0.03880081, 0.06359978, 0.00940051,\n",
       "        0.0360044 , 0.06819706, 0.00899978, 0.03700109, 0.06380153,\n",
       "        0.01020041, 0.03680153, 0.06439991, 0.00959926, 0.03440256,\n",
       "        0.07279935, 0.00859914, 0.04360213, 0.0669982 , 0.01579862,\n",
       "        0.0352026 , 0.0679985 , 0.01060262, 0.03479934, 0.06640129,\n",
       "        0.01120114, 0.03740001, 0.08240094, 0.01320105, 0.03779497,\n",
       "        0.07359848, 0.0151967 , 0.03639998, 0.08159976, 0.01140113,\n",
       "        0.04080076, 0.07039881, 0.00959959, 0.03640118, 0.07259874,\n",
       "        0.00999961, 0.03840008, 0.0686007 , 0.0092062 , 0.03260012,\n",
       "        0.06980085, 0.00940456, 0.03340359, 0.06879897, 0.00980315,\n",
       "        0.03839841, 0.07540088, 0.01320224, 0.03620176, 0.07359977,\n",
       "        0.00960083, 0.03740273, 0.06359792, 0.01159935, 0.03459792,\n",
       "        0.06739931, 0.00920048, 0.03600116, 0.06860142, 0.01420202,\n",
       "        0.03540006, 0.07179289, 0.00960188, 0.03540044, 0.0699986 ,\n",
       "        0.00900202, 0.04000154, 0.06779938, 0.01200008, 0.03600044,\n",
       "        0.0680006 , 0.00940266, 0.0334034 , 0.06939898, 0.01079998,\n",
       "        0.0380002 , 0.07040095, 0.01020203, 0.03720083, 0.07659869,\n",
       "        0.00919919, 0.03920264, 0.08339925, 0.01000109, 0.04079981,\n",
       "        0.0724009 , 0.01180053, 0.03659949, 0.07239966, 0.01060057,\n",
       "        0.03480082, 0.06600003, 0.01220117, 0.04020085, 0.0675972 ,\n",
       "        0.00940356, 0.03760204, 0.06700191, 0.00920095, 0.03639946,\n",
       "        0.06660256, 0.01179914, 0.04080195, 0.06779952, 0.01060219,\n",
       "        0.03579855, 0.08020172, 0.00960269, 0.03579936, 0.07220211,\n",
       "        0.00940032, 0.03720222, 0.06620026, 0.01080165, 0.03619986,\n",
       "        0.06679902, 0.00959864, 0.03519449, 0.06539884, 0.00960054,\n",
       "        0.03680029, 0.06880059, 0.0103991 , 0.03859963, 0.06940022,\n",
       "        0.0100009 , 0.03559947, 0.0685997 , 0.01039929, 0.03600111,\n",
       "        0.07200432, 0.00959949, 0.03580141, 0.07080088, 0.00919886,\n",
       "        0.03480144, 0.06360087, 0.00920138, 0.03940082, 0.07280035,\n",
       "        0.00960255, 0.03559923, 0.06599431, 0.00959859, 0.03480096,\n",
       "        0.06840043, 0.00920095, 0.03759937, 0.06700311, 0.00960112,\n",
       "        0.03479919, 0.06340079, 0.01020007, 0.0374073 , 0.08240166,\n",
       "        0.00939946, 0.03459902, 0.06660151, 0.0159996 , 0.03620133,\n",
       "        0.06639819, 0.00900078, 0.03440156, 0.06720128, 0.0098011 ,\n",
       "        0.0346014 , 0.06580482, 0.0092    , 0.03639884, 0.06320114,\n",
       "        0.01000113, 0.03580365, 0.06960044, 0.01260114, 0.03820047,\n",
       "        0.07320366, 0.01040053, 0.03799758, 0.07600107, 0.00960007,\n",
       "        0.0380002 , 0.0716011 , 0.00879974, 0.03420053, 0.06940022,\n",
       "        0.01000075, 0.03359866, 0.06640296, 0.00939884, 0.03639984,\n",
       "        0.06419978, 0.01019983, 0.03760047, 0.06900082, 0.00920038,\n",
       "        0.03559923, 0.06959734, 0.0095993 , 0.03860292, 0.08040085,\n",
       "        0.00960083, 0.0429997 , 0.06919932, 0.01040072, 0.03420033,\n",
       "        0.06759796, 0.01000166, 0.03640079, 0.06960015, 0.0103971 ,\n",
       "        0.03299971, 0.06440163, 0.01379776, 0.03500123, 0.06640072,\n",
       "        0.01140051, 0.04859881, 0.06859965, 0.01039963, 0.03600121,\n",
       "        0.07540536, 0.01140065, 0.03820229, 0.07300034, 0.01000013,\n",
       "        0.0385983 , 0.07180028, 0.01019864, 0.04120016, 0.07079992,\n",
       "        0.00980091, 0.03399892, 0.07259917, 0.00959926, 0.03780198,\n",
       "        0.0646029 , 0.00939927, 0.04139895, 0.0680017 , 0.0096025 ,\n",
       "        0.03880019, 0.07519989, 0.0096005 , 0.04679976, 0.06660171,\n",
       "        0.01000004, 0.03539953, 0.07079887, 0.00939956, 0.03459144,\n",
       "        0.06979942, 0.00879898, 0.0368021 , 0.06620321, 0.0092021 ,\n",
       "        0.03640089, 0.06520095, 0.00960107, 0.03740063, 0.06899714,\n",
       "        0.00979943, 0.03419514, 0.07020025, 0.00960116, 0.0408011 ,\n",
       "        0.06520214, 0.00920243, 0.03579979, 0.07120018, 0.00939703,\n",
       "        0.03620009, 0.07020035, 0.01220055, 0.03900151, 0.07460141,\n",
       "        0.00959911, 0.0362    , 0.07559943, 0.0098001 , 0.03739996,\n",
       "        0.06579967, 0.01140099, 0.03260083, 0.07840052, 0.00900035,\n",
       "        0.03659644, 0.06840005, 0.00979929, 0.03640151, 0.07739973,\n",
       "        0.00919905, 0.03600035, 0.06560011, 0.00999999, 0.03640275,\n",
       "        0.06620011, 0.00919957, 0.0340003 , 0.06640162, 0.00959973,\n",
       "        0.03460088, 0.07120018, 0.00940022, 0.03619876, 0.08199906,\n",
       "        0.00919867, 0.03559999, 0.06860051, 0.00919833, 0.03680072,\n",
       "        0.06659999, 0.01020007, 0.03359942, 0.05021582]),\n",
       " 'std_score_time': array([2.38676560e-03, 2.32426886e-03, 5.09840734e-03, 1.16724277e-03,\n",
       "        1.72155397e-03, 7.98406823e-03, 4.02405014e-03, 2.73006157e-03,\n",
       "        3.65605122e-03, 4.86358180e-04, 3.36848850e-03, 4.95510124e-03,\n",
       "        4.05887850e-04, 2.65490074e-03, 7.09550868e-03, 4.02457934e-04,\n",
       "        4.40125797e-03, 3.00773897e-03, 3.81469727e-06, 6.41778224e-03,\n",
       "        1.03182678e-02, 7.48801601e-04, 5.89099819e-03, 1.09188830e-03,\n",
       "        4.90410139e-04, 4.89010188e-04, 1.49732624e-03, 7.45744513e-04,\n",
       "        2.03806306e-03, 1.62487934e-03, 4.91152226e-04, 3.57561236e-03,\n",
       "        3.52563354e-03, 6.31657301e-04, 1.16778500e-03, 2.57635941e-03,\n",
       "        7.49145418e-04, 1.49772000e-03, 1.46883569e-03, 7.47463237e-04,\n",
       "        1.03210830e-02, 6.04706727e-03, 4.90096483e-04, 1.59153285e-02,\n",
       "        1.71285368e-02, 2.92531447e-03, 4.40906068e-03, 9.81419863e-04,\n",
       "        8.01051817e-04, 1.19759749e-03, 1.35818174e-03, 4.88423442e-04,\n",
       "        2.78702349e-03, 1.35806079e-03, 7.99683827e-04, 5.82442916e-03,\n",
       "        3.70890139e-03, 4.89139492e-04, 1.67665500e-03, 1.18639889e-02,\n",
       "        6.33089040e-04, 3.18643130e-03, 2.28058305e-03, 2.91961484e-03,\n",
       "        4.78858402e-03, 5.00319744e-03, 1.35705652e-03, 4.11583727e-03,\n",
       "        3.00758135e-03, 4.89478989e-04, 2.45071925e-03, 1.93322733e-03,\n",
       "        1.66142000e-06, 6.13246613e-03, 1.72016893e-03, 7.50395950e-04,\n",
       "        3.87014455e-03, 1.49701974e-03, 1.01938454e-03, 1.85317837e-03,\n",
       "        1.16505538e-02, 4.89084358e-04, 8.86748924e-03, 3.34628439e-03,\n",
       "        6.61266637e-03, 1.71896647e-03, 6.78248579e-03, 1.85591110e-03,\n",
       "        2.22638455e-03, 2.94079374e-03, 1.16418259e-03, 2.33346332e-03,\n",
       "        1.22253490e-02, 4.06923909e-03, 4.66782167e-03, 1.47125850e-02,\n",
       "        4.99389246e-03, 2.80150016e-03, 1.73738555e-02, 1.85455368e-03,\n",
       "        3.18925819e-03, 1.35310619e-03, 4.88831970e-04, 1.35471604e-03,\n",
       "        7.17209154e-03, 1.96951641e-06, 2.87186043e-03, 2.24482330e-03,\n",
       "        7.48309040e-04, 8.00765268e-04, 4.87206276e-03, 4.87169326e-04,\n",
       "        1.01907326e-03, 5.49209701e-03, 1.16419580e-03, 3.87562681e-03,\n",
       "        1.17408991e-02, 7.90799003e-03, 4.07132481e-03, 1.98542832e-02,\n",
       "        4.89552188e-04, 5.38563394e-03, 2.57869456e-03, 3.66620644e-03,\n",
       "        1.95861452e-03, 2.87044548e-03, 4.01438258e-04, 3.34686781e-03,\n",
       "        5.78338271e-03, 9.92577726e-03, 3.32002675e-03, 7.56180860e-03,\n",
       "        7.99802611e-04, 1.62588833e-03, 6.13348496e-03, 6.31732169e-04,\n",
       "        6.41858447e-03, 5.87691366e-03, 3.79532533e-03, 3.03442387e-03,\n",
       "        3.79649388e-03, 8.00779440e-04, 1.20351699e-03, 4.49934076e-03,\n",
       "        2.63790332e-03, 2.45016908e-03, 2.79998836e-03, 4.00856344e-04,\n",
       "        5.03654049e-03, 8.95768173e-03, 3.98858604e-04, 1.32986886e-03,\n",
       "        1.65598960e-02, 6.32109545e-04, 9.21705143e-03, 2.41531747e-03,\n",
       "        5.11578538e-03, 8.01492097e-04, 7.91461949e-03, 1.62308270e-03,\n",
       "        1.16635123e-03, 2.28043681e-03, 2.78553413e-03, 3.59919909e-03,\n",
       "        2.94254336e-03, 8.03138393e-04, 6.74734320e-03, 2.44789134e-03,\n",
       "        4.00353671e-04, 1.85663184e-03, 1.35696541e-03, 3.25067128e-03,\n",
       "        8.35272234e-03, 3.05714254e-03, 1.35695931e-03, 3.65641880e-03,\n",
       "        1.66875071e-02, 4.92874295e-04, 2.48068305e-03, 1.65438676e-02,\n",
       "        4.89533284e-04, 3.43107398e-03, 2.13554706e-03, 7.47145408e-04,\n",
       "        4.70788664e-03, 2.78501735e-03, 4.91071011e-04, 1.15809591e-03,\n",
       "        1.62390098e-03, 8.01396602e-04, 4.44667422e-03, 1.83223271e-03,\n",
       "        2.33305514e-03, 4.40913425e-03, 2.87086359e-03, 6.35200314e-04,\n",
       "        1.62507750e-03, 2.24630160e-03, 1.35765468e-03, 1.57139369e-06,\n",
       "        2.83227535e-03, 4.88270246e-04, 1.16675212e-03, 3.81548290e-03,\n",
       "        7.47198995e-04, 1.93936892e-03, 1.96071544e-03, 7.47347771e-04,\n",
       "        8.56853228e-03, 4.44733076e-03, 8.00193590e-04, 2.15344952e-03,\n",
       "        2.67297996e-03, 7.98455066e-04, 2.63827272e-03, 1.85412144e-03,\n",
       "        7.48802528e-04, 5.08284009e-03, 5.18083566e-03, 4.92125564e-04,\n",
       "        2.13814686e-03, 2.41637106e-03, 1.93951202e-03, 5.32918968e-03,\n",
       "        1.45557564e-02, 4.90137419e-04, 1.35551817e-03, 2.41760335e-03,\n",
       "        1.35053770e-02, 2.92580305e-03, 4.12647590e-03, 6.32412766e-04,\n",
       "        1.35588011e-03, 5.03413591e-03, 7.49273959e-04, 1.62544746e-03,\n",
       "        1.94476626e-03, 7.48738273e-04, 2.05980204e-03, 1.16586125e-03,\n",
       "        6.33541852e-04, 1.72035769e-03, 4.31733674e-03, 5.71252182e-03,\n",
       "        3.86897118e-03, 5.07518284e-03, 1.20127298e-03, 2.27178298e-03,\n",
       "        6.89864397e-03, 4.89610083e-04, 3.74206199e-03, 7.73597612e-03,\n",
       "        3.99090950e-04, 1.46911381e-03, 3.49786812e-03, 8.94043240e-04,\n",
       "        1.02165663e-03, 3.00552864e-03, 7.99465649e-04, 2.57689580e-03,\n",
       "        1.72231975e-03, 7.49144599e-04, 4.41055519e-03, 7.48235190e-03,\n",
       "        7.47361763e-04, 1.62513716e-03, 1.28709786e-02, 4.89380501e-04,\n",
       "        5.91985229e-03, 1.97455797e-02, 1.02117073e-03, 2.05137250e-02,\n",
       "        1.60005756e-03, 1.49797678e-03, 7.48927985e-04, 2.57687355e-03,\n",
       "        6.33465378e-04, 4.02969357e-03, 6.49953463e-03, 4.93597855e-04,\n",
       "        1.26557360e-03, 2.87010386e-03, 9.10319497e-03, 2.68312299e-03,\n",
       "        6.40540059e-03, 5.31495663e-03, 1.74530612e-02, 2.15459309e-03,\n",
       "        8.00824369e-04, 1.41397668e-03, 5.08872022e-03, 2.06114517e-03,\n",
       "        4.06972248e-03, 5.17580564e-03, 8.94149301e-04, 2.24256399e-03,\n",
       "        5.30668246e-03, 4.00889888e-04, 9.10800677e-03, 1.71904372e-03,\n",
       "        7.48776085e-04, 1.78997821e-03, 8.91314449e-03, 7.99621017e-04,\n",
       "        3.81581543e-03, 1.49281753e-03, 8.00744628e-04, 9.56165165e-03,\n",
       "        2.60668845e-03, 7.99820166e-04, 4.01984437e-03, 1.37768399e-02,\n",
       "        4.90058625e-04, 1.45517836e-02, 3.77423927e-03, 1.41549477e-03,\n",
       "        3.55632654e-03, 6.42847604e-03, 4.90449876e-04, 1.00737911e-03,\n",
       "        8.51788288e-03, 7.48941617e-04, 5.70600830e-03, 2.63783906e-03,\n",
       "        4.00977030e-04, 3.38608824e-03, 5.48890657e-03, 8.00586121e-04,\n",
       "        3.19979811e-03, 4.42740296e-03, 7.47936957e-04, 1.17191037e-03,\n",
       "        9.51634180e-03, 1.02031994e-03, 8.08348960e-03, 1.16472684e-03,\n",
       "        3.97957031e-04, 1.32716603e-03, 4.70794716e-03, 8.01761930e-04,\n",
       "        1.46967174e-03, 4.49051528e-03, 2.03953037e-03, 2.82709422e-03,\n",
       "        8.01382325e-03, 4.91556220e-04, 4.01402738e-04, 8.40390295e-03,\n",
       "        7.48877131e-04, 5.88587524e-03, 3.18723899e-03, 3.38341250e-03,\n",
       "        4.90038831e-04, 1.31220337e-02, 8.93563030e-04, 4.45837349e-03,\n",
       "        5.35157714e-03, 7.50133135e-04, 3.49811643e-03, 1.15502627e-02,\n",
       "        4.01188654e-04, 2.27949573e-03, 2.05913446e-03, 8.94097073e-04,\n",
       "        3.93364028e-03, 1.60099950e-03, 7.50190951e-04, 1.67405381e-03,\n",
       "        1.49601306e-03, 1.02153548e-03, 1.95931399e-03, 3.65573764e-03,\n",
       "        7.99846777e-04, 3.54421296e-03, 1.57101607e-02, 4.00187925e-04,\n",
       "        2.79985854e-03, 4.31719313e-03, 4.01810067e-04, 2.22714225e-03,\n",
       "        2.93866272e-03, 3.99925869e-04, 1.02036627e-03, 4.41199793e-03]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_impurity_decrease': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
       "                    0.15, 0.15, 0.15, 0.15, 0.15, 0.15],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[10, 10, 10, 15, 15, 15, 20, 20, 20, 25, 25, 25, 10, 10,\n",
       "                    10, 15, 15, 15, 20, 20, 20, 25, 25, 25, 10, 10, 10, 15,\n",
       "                    15, 15, 20, 20, 20, 25, 25, 25, 10, 10, 10, 15, 15, 15,\n",
       "                    20, 20, 20, 25, 25, 25, 10, 10, 10, 15, 15, 15, 20, 20,\n",
       "                    20, 25, 25, 25, 10, 10, 10, 15, 15, 15, 20, 20, 20, 25,\n",
       "                    25, 25, 10, 10, 10, 15, 15, 15, 20, 20, 20, 25, 25, 25,\n",
       "                    10, 10, 10, 15, 15, 15, 20, 20, 20, 25, 25, 25, 10, 10,\n",
       "                    10, 15, 15, 15, 20, 20, 20, 25, 25, 25, 10, 10, 10, 15,\n",
       "                    15, 15, 20, 20, 20, 25, 25, 25, 10, 10, 10, 15, 15, 15,\n",
       "                    20, 20, 20, 25, 25, 25, 10, 10, 10, 15, 15, 15, 20, 20,\n",
       "                    20, 25, 25, 25, 10, 10, 10, 15, 15, 15, 20, 20, 20, 25,\n",
       "                    25, 25, 10, 10, 10, 15, 15, 15, 20, 20, 20, 25, 25, 25,\n",
       "                    10, 10, 10, 15, 15, 15, 20, 20, 20, 25, 25, 25, 10, 10,\n",
       "                    10, 15, 15, 15, 20, 20, 20, 25, 25, 25, 10, 10, 10, 15,\n",
       "                    15, 15, 20, 20, 20, 25, 25, 25, 10, 10, 10, 15, 15, 15,\n",
       "                    20, 20, 20, 25, 25, 25, 10, 10, 10, 15, 15, 15, 20, 20,\n",
       "                    20, 25, 25, 25, 10, 10, 10, 15, 15, 15, 20, 20, 20, 25,\n",
       "                    25, 25, 10, 10, 10, 15, 15, 15, 20, 20, 20, 25, 25, 25,\n",
       "                    10, 10, 10, 15, 15, 15, 20, 20, 20, 25, 25, 25, 10, 10,\n",
       "                    10, 15, 15, 15, 20, 20, 20, 25, 25, 25, 10, 10, 10, 15,\n",
       "                    15, 15, 20, 20, 20, 25, 25, 25, 10, 10, 10, 15, 15, 15,\n",
       "                    20, 20, 20, 25, 25, 25, 10, 10, 10, 15, 15, 15, 20, 20,\n",
       "                    20, 25, 25, 25, 10, 10, 10, 15, 15, 15, 20, 20, 20, 25,\n",
       "                    25, 25, 10, 10, 10, 15, 15, 15, 20, 20, 20, 25, 25, 25,\n",
       "                    10, 10, 10, 15, 15, 15, 20, 20, 20, 25, 25, 25, 10, 10,\n",
       "                    10, 15, 15, 15, 20, 20, 20, 25, 25, 25, 10, 10, 10, 15,\n",
       "                    15, 15, 20, 20, 20, 25, 25, 25, 10, 10, 10, 15, 15, 15,\n",
       "                    20, 20, 20, 25, 25, 25],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10,\n",
       "                    50, 100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.001,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.1,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 20,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_impurity_decrease': 0.15,\n",
       "   'min_samples_leaf': 25,\n",
       "   'n_estimators': 100}],\n",
       " 'split0_test_score': array([0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.52281803,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.5225328 , 0.5179692 , 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51739875, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829]),\n",
       " 'split1_test_score': array([0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.53094695, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51697091, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51697091, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51882487,\n",
       "        0.51682829, 0.51682829, 0.52966343, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829]),\n",
       " 'split2_test_score': array([0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.52766686, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.52067884, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.52567028, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.52681118, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.52082145, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51668568, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51968055, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.52082145, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.52167712, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829]),\n",
       " 'split3_test_score': array([0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51597262,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.52124929, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.52067884,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.52167712, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.52681118,\n",
       "        0.51682829, 0.52281803, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.52638334, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51768397, 0.51811181, 0.51682829, 0.51682829,\n",
       "        0.51882487, 0.51682829, 0.51697091, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829]),\n",
       " 'split4_test_score': array([0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.52966343,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.52738163, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.52053622, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51725613,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829]),\n",
       " 'mean_test_score': array([0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51665716,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51771249, 0.51682829,\n",
       "        0.51682829, 0.51899601, 0.51682829, 0.51682829, 0.52016543,\n",
       "        0.5175984 , 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.52176269, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51859669, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.5175984 , 0.51682829,\n",
       "        0.51682829, 0.51979464, 0.51682829, 0.51682829, 0.51802624,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51762693, 0.51882487,\n",
       "        0.51682829, 0.51805476, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51679977, 0.51988021, 0.51705647, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51756988, 0.517085  , 0.51694238, 0.51722761,\n",
       "        0.51722761, 0.51762693, 0.51942384, 0.51682829, 0.51691386,\n",
       "        0.51779806, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829]),\n",
       " 'std_test_score': array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.42270394e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.76839703e-03, 0.00000000e+00, 0.00000000e+00, 4.33542499e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.97765188e-03, 1.54021677e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.14764803e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.53679407e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.46994851e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.97927667e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.39589276e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.59726184e-03, 3.99315459e-03, 0.00000000e+00, 2.38227188e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.70450656e-05, 3.93114596e-03, 4.56360525e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.10614486e-03, 5.13405590e-04, 2.28180262e-04, 7.98630918e-04,\n",
       "        7.98630918e-04, 1.59726184e-03, 5.12009257e-03, 0.00000000e+00,\n",
       "        1.71135197e-04, 1.93953223e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'rank_test_score': array([ 24,  24,  24,  24,  24,  24,  24,  24,  24, 384,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  12,  24,  24,   6,\n",
       "         24,  24,   2,  15,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,   1,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,   8,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  15,  24,  24,   4,\n",
       "         24,  24,  10,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  13,   7,  24,   9,  24,  24,  24,  24, 383,   3,  21,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  17,  20,\n",
       "         22,  18,  18,  13,   5,  24,  23,  11,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "         24,  24,  24,  24,  24,  24,  24]),\n",
       " 'split0_train_score': array([0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.52852253,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.5292356 , 0.51836138, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51786224, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829]),\n",
       " 'split1_train_score': array([0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.52734598, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51686395, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.5236024 ,\n",
       "        0.51718483, 0.51682829, 0.52777382, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829]),\n",
       " 'split2_train_score': array([0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.52805904, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.53066172, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.52684683, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.53001997, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.53073303, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51697091, 0.51736309, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.52727467, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.52720337, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.53023388, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829]),\n",
       " 'split3_train_score': array([0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.52773816,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.53183828, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.52902168,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.53166001, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51686395, 0.52841557,\n",
       "        0.51682829, 0.5304478 , 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.52695379, 0.51704221, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.52527809, 0.51782658, 0.51682829, 0.51682829,\n",
       "        0.51878922, 0.51682829, 0.5168996 , 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829]),\n",
       " 'split4_train_score': array([0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.52977039,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.5270251 , 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.52638334, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51722048,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829]),\n",
       " 'mean_train_score': array([0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51901027,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51983029, 0.51682829,\n",
       "        0.51682829, 0.51907444, 0.51682829, 0.51682829, 0.52185539,\n",
       "        0.51959498, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.52097119, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.518832  , 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.5187393 , 0.51682829,\n",
       "        0.51682829, 0.52243297, 0.51682829, 0.51682829, 0.51916714,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51961637, 0.51914575,\n",
       "        0.51682829, 0.51955933, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51685682, 0.51693525, 0.52133485, 0.5171777 , 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.52060753, 0.51702795, 0.51703508, 0.51818311,\n",
       "        0.51729179, 0.51890331, 0.51903166, 0.51682829, 0.51690673,\n",
       "        0.51950941, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829, 0.51682829,\n",
       "        0.51682829, 0.51682829, 0.51682829, 0.51682829]),\n",
       " 'std_train_score': array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.36394752e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.00399315e-03, 0.00000000e+00, 0.00000000e+00, 4.49229892e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.16146128e-03, 5.53337136e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.07500746e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.00741586e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.82201940e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.88386469e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.67769538e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.55834573e-03, 4.63491158e-03, 0.00000000e+00, 5.44425596e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.70450656e-05,\n",
       "        2.13918996e-04, 5.56635333e-03, 5.97613430e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.67146279e-03, 3.99315459e-04, 4.13576726e-04, 2.70964062e-03,\n",
       "        7.61343287e-04, 4.15002852e-03, 4.37116539e-03, 0.00000000e+00,\n",
       "        1.56873930e-04, 5.36223617e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tree.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not help us much, but notice how everything is in dictionaries? Let's use that to put this into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_df = pd.DataFrame(gs_tree.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_impurity_decrease</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.165006</td>\n",
       "      <td>0.010762</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.741801</td>\n",
       "      <td>0.011090</td>\n",
       "      <td>0.031606</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.546198</td>\n",
       "      <td>0.061093</td>\n",
       "      <td>0.057999</td>\n",
       "      <td>0.005098</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.161998</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.837600</td>\n",
       "      <td>0.044380</td>\n",
       "      <td>0.030801</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.165006      0.010762         0.014194        0.002387   \n",
       "1       0.741801      0.011090         0.031606        0.002324   \n",
       "2       1.546198      0.061093         0.057999        0.005098   \n",
       "3       0.161998      0.004428         0.008801        0.001167   \n",
       "4       0.837600      0.044380         0.030801        0.001722   \n",
       "\n",
       "  param_criterion param_max_depth param_min_impurity_decrease  \\\n",
       "0            gini               1                       0.001   \n",
       "1            gini               1                       0.001   \n",
       "2            gini               1                       0.001   \n",
       "3            gini               1                       0.001   \n",
       "4            gini               1                       0.001   \n",
       "\n",
       "  param_min_samples_leaf param_n_estimators  \\\n",
       "0                     10                 10   \n",
       "1                     10                 50   \n",
       "2                     10                100   \n",
       "3                     15                 10   \n",
       "4                     15                 50   \n",
       "\n",
       "                                              params  ...  mean_test_score  \\\n",
       "0  {'criterion': 'gini', 'max_depth': 1, 'min_imp...  ...         0.516828   \n",
       "1  {'criterion': 'gini', 'max_depth': 1, 'min_imp...  ...         0.516828   \n",
       "2  {'criterion': 'gini', 'max_depth': 1, 'min_imp...  ...         0.516828   \n",
       "3  {'criterion': 'gini', 'max_depth': 1, 'min_imp...  ...         0.516828   \n",
       "4  {'criterion': 'gini', 'max_depth': 1, 'min_imp...  ...         0.516828   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0             0.0               24            0.516828            0.516828   \n",
       "1             0.0               24            0.516828            0.516828   \n",
       "2             0.0               24            0.516828            0.516828   \n",
       "3             0.0               24            0.516828            0.516828   \n",
       "4             0.0               24            0.516828            0.516828   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.516828            0.516828            0.516828   \n",
       "1            0.516828            0.516828            0.516828   \n",
       "2            0.516828            0.516828            0.516828   \n",
       "3            0.516828            0.516828            0.516828   \n",
       "4            0.516828            0.516828            0.516828   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.516828              0.0  \n",
       "1          0.516828              0.0  \n",
       "2          0.516828              0.0  \n",
       "3          0.516828              0.0  \n",
       "4          0.516828              0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the columns are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_criterion', 'param_max_depth', 'param_min_impurity_decrease',\n",
       "       'param_min_samples_leaf', 'param_n_estimators', 'params',\n",
       "       'split0_test_score', 'split1_test_score', 'split2_test_score',\n",
       "       'split3_test_score', 'split4_test_score', 'mean_test_score',\n",
       "       'std_test_score', 'rank_test_score', 'split0_train_score',\n",
       "       'split1_train_score', 'split2_train_score', 'split3_train_score',\n",
       "       'split4_train_score', 'mean_train_score', 'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_impurity_decrease</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.309199</td>\n",
       "      <td>0.036454</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521763</td>\n",
       "      <td>0.006148</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.527346</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.527025</td>\n",
       "      <td>0.520971</td>\n",
       "      <td>0.005075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.276994</td>\n",
       "      <td>0.023886</td>\n",
       "      <td>0.009401</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520165</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>2</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.529022</td>\n",
       "      <td>0.529770</td>\n",
       "      <td>0.521855</td>\n",
       "      <td>0.006161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.451798</td>\n",
       "      <td>0.091456</td>\n",
       "      <td>0.010199</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519880</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>3</td>\n",
       "      <td>0.529236</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.526954</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.521335</td>\n",
       "      <td>0.005566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.397995</td>\n",
       "      <td>0.025966</td>\n",
       "      <td>0.010401</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519795</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>4</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.530020</td>\n",
       "      <td>0.531660</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.522433</td>\n",
       "      <td>0.006884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0.509799</td>\n",
       "      <td>0.077281</td>\n",
       "      <td>0.012201</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519424</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.527774</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516900</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519032</td>\n",
       "      <td>0.004371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.272396</td>\n",
       "      <td>0.023398</td>\n",
       "      <td>0.009399</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518996</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>6</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.528059</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519074</td>\n",
       "      <td>0.004492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>2.194199</td>\n",
       "      <td>0.248337</td>\n",
       "      <td>0.036001</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518825</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>7</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.528416</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519146</td>\n",
       "      <td>0.004635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.301597</td>\n",
       "      <td>0.025894</td>\n",
       "      <td>0.010202</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_im...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518597</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>8</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.526847</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518832</td>\n",
       "      <td>0.004007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.462799</td>\n",
       "      <td>0.034395</td>\n",
       "      <td>0.011401</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518055</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>9</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516864</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.530448</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519559</td>\n",
       "      <td>0.005444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.379597</td>\n",
       "      <td>0.056790</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518026</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>10</td>\n",
       "      <td>0.528523</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519167</td>\n",
       "      <td>0.004678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0.432797</td>\n",
       "      <td>0.060981</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517798</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>11</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.530234</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519509</td>\n",
       "      <td>0.005362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.271398</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>0.009601</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517712</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>12</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.531838</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519830</td>\n",
       "      <td>0.006004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.417799</td>\n",
       "      <td>0.041013</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517627</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>13</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.530733</td>\n",
       "      <td>0.516864</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519616</td>\n",
       "      <td>0.005558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>4.325398</td>\n",
       "      <td>0.556493</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517627</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>13</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.527203</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518903</td>\n",
       "      <td>0.004150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.288013</td>\n",
       "      <td>0.027975</td>\n",
       "      <td>0.040385</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517598</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>15</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.530662</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519595</td>\n",
       "      <td>0.005533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.445596</td>\n",
       "      <td>0.072297</td>\n",
       "      <td>0.012601</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517598</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>15</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.526383</td>\n",
       "      <td>0.518739</td>\n",
       "      <td>0.003822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.438998</td>\n",
       "      <td>0.068833</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517570</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>17</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.527275</td>\n",
       "      <td>0.525278</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.520608</td>\n",
       "      <td>0.004671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2.132798</td>\n",
       "      <td>0.190474</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517228</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>18</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517185</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518789</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517292</td>\n",
       "      <td>0.000761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.439401</td>\n",
       "      <td>0.033704</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517228</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>18</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.523602</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518183</td>\n",
       "      <td>0.002710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2.119398</td>\n",
       "      <td>0.085510</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517085</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>20</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517827</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517028</td>\n",
       "      <td>0.000399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2.166600</td>\n",
       "      <td>0.165213</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517056</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>21</td>\n",
       "      <td>0.518361</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517042</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517178</td>\n",
       "      <td>0.000598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>4.163400</td>\n",
       "      <td>0.349124</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516942</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>22</td>\n",
       "      <td>0.517862</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517035</td>\n",
       "      <td>0.000414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>4.266597</td>\n",
       "      <td>0.354899</td>\n",
       "      <td>0.074601</td>\n",
       "      <td>0.008014</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516914</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>23</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517220</td>\n",
       "      <td>0.516907</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2.831200</td>\n",
       "      <td>0.163244</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>3.654998</td>\n",
       "      <td>0.073115</td>\n",
       "      <td>0.076001</td>\n",
       "      <td>0.006899</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1.838003</td>\n",
       "      <td>0.093359</td>\n",
       "      <td>0.037998</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>3.618598</td>\n",
       "      <td>0.101651</td>\n",
       "      <td>0.073204</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1.777398</td>\n",
       "      <td>0.066715</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>3.663796</td>\n",
       "      <td>0.170172</td>\n",
       "      <td>0.071601</td>\n",
       "      <td>0.007736</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>1.774797</td>\n",
       "      <td>0.063039</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2.783195</td>\n",
       "      <td>0.082323</td>\n",
       "      <td>0.072599</td>\n",
       "      <td>0.007172</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1.500199</td>\n",
       "      <td>0.120753</td>\n",
       "      <td>0.036401</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.354994</td>\n",
       "      <td>0.046018</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>3.054400</td>\n",
       "      <td>0.241892</td>\n",
       "      <td>0.070399</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1.050599</td>\n",
       "      <td>0.129174</td>\n",
       "      <td>0.037403</td>\n",
       "      <td>0.005386</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2.123600</td>\n",
       "      <td>0.223045</td>\n",
       "      <td>0.063598</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.256596</td>\n",
       "      <td>0.034172</td>\n",
       "      <td>0.011599</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1.952402</td>\n",
       "      <td>0.014304</td>\n",
       "      <td>0.069999</td>\n",
       "      <td>0.006133</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1.933798</td>\n",
       "      <td>0.024384</td>\n",
       "      <td>0.069399</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.950399</td>\n",
       "      <td>0.013543</td>\n",
       "      <td>0.033403</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.208998</td>\n",
       "      <td>0.015112</td>\n",
       "      <td>0.009403</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1.938599</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.068001</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.979796</td>\n",
       "      <td>0.034349</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.236796</td>\n",
       "      <td>0.027811</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2.166600</td>\n",
       "      <td>0.202731</td>\n",
       "      <td>0.067799</td>\n",
       "      <td>0.005877</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.995999</td>\n",
       "      <td>0.030789</td>\n",
       "      <td>0.040002</td>\n",
       "      <td>0.006419</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.041098</td>\n",
       "      <td>0.034598</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.209197</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.961196</td>\n",
       "      <td>0.016435</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.212195</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.009602</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1.998806</td>\n",
       "      <td>0.103331</td>\n",
       "      <td>0.071793</td>\n",
       "      <td>0.007562</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.970398</td>\n",
       "      <td>0.025162</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.205798</td>\n",
       "      <td>0.007439</td>\n",
       "      <td>0.014202</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.973199</td>\n",
       "      <td>0.026603</td>\n",
       "      <td>0.068601</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.954998</td>\n",
       "      <td>0.035951</td>\n",
       "      <td>0.036001</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.207398</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1.937798</td>\n",
       "      <td>0.034734</td>\n",
       "      <td>0.067399</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2.297397</td>\n",
       "      <td>0.035307</td>\n",
       "      <td>0.050216</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>4.298598</td>\n",
       "      <td>0.537318</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516800</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>383</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517363</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516935</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.173003</td>\n",
       "      <td>0.009055</td>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516657</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>384</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.527738</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519010</td>\n",
       "      <td>0.004364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "105       0.309199      0.036454         0.010000        0.000002   \n",
       "54        0.276994      0.023886         0.009401        0.000800   \n",
       "297       0.451798      0.091456         0.010199        0.000401   \n",
       "246       0.397995      0.025966         0.010401        0.001201   \n",
       "342       0.509799      0.077281         0.012201        0.002040   \n",
       "51        0.272396      0.023398         0.009399        0.000488   \n",
       "289       2.194199      0.248337         0.036001        0.001414   \n",
       "147       0.301597      0.025894         0.010202        0.000401   \n",
       "291       0.462799      0.034395         0.011401        0.002061   \n",
       "249       0.379597      0.056790         0.009600        0.000490   \n",
       "345       0.432797      0.060981         0.009599        0.000492   \n",
       "48        0.271398      0.006917         0.009601        0.000801   \n",
       "288       0.417799      0.041013         0.010400        0.000801   \n",
       "341       4.325398      0.556493         0.070200        0.004491   \n",
       "55        1.288013      0.027975         0.040385        0.005824   \n",
       "243       0.445596      0.072297         0.012601        0.005713   \n",
       "336       0.438998      0.068833         0.009202        0.000398   \n",
       "340       2.132798      0.190474         0.036200        0.001470   \n",
       "339       0.439401      0.033704         0.009397        0.000802   \n",
       "337       2.119398      0.085510         0.035800        0.001327   \n",
       "298       2.166600      0.165213         0.041200        0.009108   \n",
       "338       4.163400      0.349124         0.071200        0.004708   \n",
       "344       4.266597      0.354899         0.074601        0.008014   \n",
       "254       2.831200      0.163244         0.069400        0.003498   \n",
       "248       3.654998      0.073115         0.076001        0.006899   \n",
       "247       1.838003      0.093359         0.037998        0.002272   \n",
       "245       3.618598      0.101651         0.073204        0.005075   \n",
       "250       1.777398      0.066715         0.038000        0.003742   \n",
       "251       3.663796      0.170172         0.071601        0.007736   \n",
       "244       1.774797      0.063039         0.038200        0.003869   \n",
       "..             ...           ...              ...             ...   \n",
       "104       2.783195      0.082323         0.072599        0.007172   \n",
       "103       1.500199      0.120753         0.036401        0.001355   \n",
       "102       0.354994      0.046018         0.009600        0.000489   \n",
       "101       3.054400      0.241892         0.070399        0.001353   \n",
       "121       1.050599      0.129174         0.037403        0.005386   \n",
       "122       2.123600      0.223045         0.063598        0.002579   \n",
       "123       0.256596      0.034172         0.011599        0.003666   \n",
       "134       1.952402      0.014304         0.069999        0.006133   \n",
       "143       1.933798      0.024384         0.069399        0.004499   \n",
       "142       0.950399      0.013543         0.033403        0.001204   \n",
       "141       0.208998      0.015112         0.009403        0.000801   \n",
       "140       1.938599      0.055398         0.068001        0.003796   \n",
       "139       0.979796      0.034349         0.036000        0.003034   \n",
       "138       0.236796      0.027811         0.012000        0.003795   \n",
       "137       2.166600      0.202731         0.067799        0.005877   \n",
       "136       0.995999      0.030789         0.040002        0.006419   \n",
       "124       0.987000      0.041098         0.034598        0.001959   \n",
       "135       0.209197      0.004836         0.009002        0.000632   \n",
       "133       0.961196      0.016435         0.035400        0.001626   \n",
       "132       0.212195      0.016905         0.009602        0.000800   \n",
       "131       1.998806      0.103331         0.071793        0.007562   \n",
       "130       0.970398      0.025162         0.035400        0.003320   \n",
       "129       0.205798      0.007439         0.014202        0.009926   \n",
       "128       1.973199      0.026603         0.068601        0.005783   \n",
       "127       0.954998      0.035951         0.036001        0.003347   \n",
       "126       0.207398      0.006946         0.009200        0.000401   \n",
       "125       1.937798      0.034734         0.067399        0.002870   \n",
       "383       2.297397      0.035307         0.050216        0.004412   \n",
       "296       4.298598      0.537318         0.071800        0.005307   \n",
       "9         0.173003      0.009055         0.007597        0.000486   \n",
       "\n",
       "    param_criterion param_max_depth param_min_impurity_decrease  \\\n",
       "105            gini               5                       0.001   \n",
       "54             gini               2                       0.001   \n",
       "297         entropy               5                       0.001   \n",
       "246         entropy               2                       0.001   \n",
       "342         entropy              10                       0.001   \n",
       "51             gini               2                       0.001   \n",
       "289         entropy               5                       0.001   \n",
       "147            gini              10                       0.001   \n",
       "291         entropy               5                       0.001   \n",
       "249         entropy               2                       0.001   \n",
       "345         entropy              10                       0.001   \n",
       "48             gini               2                       0.001   \n",
       "288         entropy               5                       0.001   \n",
       "341         entropy              10                       0.001   \n",
       "55             gini               2                       0.001   \n",
       "243         entropy               2                       0.001   \n",
       "336         entropy              10                       0.001   \n",
       "340         entropy              10                       0.001   \n",
       "339         entropy              10                       0.001   \n",
       "337         entropy              10                       0.001   \n",
       "298         entropy               5                       0.001   \n",
       "338         entropy              10                       0.001   \n",
       "344         entropy              10                       0.001   \n",
       "254         entropy               2                        0.01   \n",
       "248         entropy               2                       0.001   \n",
       "247         entropy               2                       0.001   \n",
       "245         entropy               2                       0.001   \n",
       "250         entropy               2                       0.001   \n",
       "251         entropy               2                       0.001   \n",
       "244         entropy               2                       0.001   \n",
       "..              ...             ...                         ...   \n",
       "104            gini               5                       0.001   \n",
       "103            gini               5                       0.001   \n",
       "102            gini               5                       0.001   \n",
       "101            gini               5                       0.001   \n",
       "121            gini               5                         0.1   \n",
       "122            gini               5                         0.1   \n",
       "123            gini               5                         0.1   \n",
       "134            gini               5                        0.15   \n",
       "143            gini               5                        0.15   \n",
       "142            gini               5                        0.15   \n",
       "141            gini               5                        0.15   \n",
       "140            gini               5                        0.15   \n",
       "139            gini               5                        0.15   \n",
       "138            gini               5                        0.15   \n",
       "137            gini               5                        0.15   \n",
       "136            gini               5                        0.15   \n",
       "124            gini               5                         0.1   \n",
       "135            gini               5                        0.15   \n",
       "133            gini               5                        0.15   \n",
       "132            gini               5                        0.15   \n",
       "131            gini               5                         0.1   \n",
       "130            gini               5                         0.1   \n",
       "129            gini               5                         0.1   \n",
       "128            gini               5                         0.1   \n",
       "127            gini               5                         0.1   \n",
       "126            gini               5                         0.1   \n",
       "125            gini               5                         0.1   \n",
       "383         entropy              10                        0.15   \n",
       "296         entropy               5                       0.001   \n",
       "9              gini               1                       0.001   \n",
       "\n",
       "    param_min_samples_leaf param_n_estimators  \\\n",
       "105                     25                 10   \n",
       "54                      20                 10   \n",
       "297                     25                 10   \n",
       "246                     20                 10   \n",
       "342                     20                 10   \n",
       "51                      15                 10   \n",
       "289                     10                 50   \n",
       "147                     15                 10   \n",
       "291                     15                 10   \n",
       "249                     25                 10   \n",
       "345                     25                 10   \n",
       "48                      10                 10   \n",
       "288                     10                 10   \n",
       "341                     15                100   \n",
       "55                      20                 50   \n",
       "243                     15                 10   \n",
       "336                     10                 10   \n",
       "340                     15                 50   \n",
       "339                     15                 10   \n",
       "337                     10                 50   \n",
       "298                     25                 50   \n",
       "338                     10                100   \n",
       "344                     20                100   \n",
       "254                     10                100   \n",
       "248                     20                100   \n",
       "247                     20                 50   \n",
       "245                     15                100   \n",
       "250                     25                 50   \n",
       "251                     25                100   \n",
       "244                     15                 50   \n",
       "..                     ...                ...   \n",
       "104                     20                100   \n",
       "103                     20                 50   \n",
       "102                     20                 10   \n",
       "101                     15                100   \n",
       "121                     10                 50   \n",
       "122                     10                100   \n",
       "123                     15                 10   \n",
       "134                     10                100   \n",
       "143                     25                100   \n",
       "142                     25                 50   \n",
       "141                     25                 10   \n",
       "140                     20                100   \n",
       "139                     20                 50   \n",
       "138                     20                 10   \n",
       "137                     15                100   \n",
       "136                     15                 50   \n",
       "124                     15                 50   \n",
       "135                     15                 10   \n",
       "133                     10                 50   \n",
       "132                     10                 10   \n",
       "131                     25                100   \n",
       "130                     25                 50   \n",
       "129                     25                 10   \n",
       "128                     20                100   \n",
       "127                     20                 50   \n",
       "126                     20                 10   \n",
       "125                     15                100   \n",
       "383                     25                100   \n",
       "296                     20                100   \n",
       "9                       25                 10   \n",
       "\n",
       "                                                params  ...  mean_test_score  \\\n",
       "105  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.521763   \n",
       "54   {'criterion': 'gini', 'max_depth': 2, 'min_imp...  ...         0.520165   \n",
       "297  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...         0.519880   \n",
       "246  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...         0.519795   \n",
       "342  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...         0.519424   \n",
       "51   {'criterion': 'gini', 'max_depth': 2, 'min_imp...  ...         0.518996   \n",
       "289  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...         0.518825   \n",
       "147  {'criterion': 'gini', 'max_depth': 10, 'min_im...  ...         0.518597   \n",
       "291  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...         0.518055   \n",
       "249  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...         0.518026   \n",
       "345  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...         0.517798   \n",
       "48   {'criterion': 'gini', 'max_depth': 2, 'min_imp...  ...         0.517712   \n",
       "288  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...         0.517627   \n",
       "341  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...         0.517627   \n",
       "55   {'criterion': 'gini', 'max_depth': 2, 'min_imp...  ...         0.517598   \n",
       "243  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...         0.517598   \n",
       "336  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...         0.517570   \n",
       "340  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...         0.517228   \n",
       "339  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...         0.517228   \n",
       "337  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...         0.517085   \n",
       "298  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...         0.517056   \n",
       "338  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...         0.516942   \n",
       "344  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...         0.516914   \n",
       "254  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...         0.516828   \n",
       "248  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...         0.516828   \n",
       "247  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...         0.516828   \n",
       "245  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...         0.516828   \n",
       "250  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...         0.516828   \n",
       "251  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...         0.516828   \n",
       "244  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...         0.516828   \n",
       "..                                                 ...  ...              ...   \n",
       "104  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "103  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "102  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "101  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "121  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "122  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "123  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "134  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "143  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "142  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "141  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "140  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "139  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "138  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "137  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "136  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "124  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "135  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "133  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "132  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "131  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "130  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "129  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "128  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "127  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "126  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "125  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...         0.516828   \n",
       "383  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...         0.516828   \n",
       "296  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...         0.516800   \n",
       "9    {'criterion': 'gini', 'max_depth': 1, 'min_imp...  ...         0.516657   \n",
       "\n",
       "     std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "105        0.006148                1            0.516828            0.527346   \n",
       "54         0.004978                2            0.516828            0.516828   \n",
       "297        0.003931                3            0.529236            0.516828   \n",
       "246        0.003979                4            0.516828            0.516828   \n",
       "342        0.005120                5            0.516828            0.527774   \n",
       "51         0.004335                6            0.516828            0.516828   \n",
       "289        0.003993                7            0.516828            0.516828   \n",
       "147        0.003537                8            0.516828            0.516828   \n",
       "291        0.002382                9            0.516828            0.516864   \n",
       "249        0.002396               10            0.528523            0.516828   \n",
       "345        0.001940               11            0.516828            0.516828   \n",
       "48         0.001768               12            0.516828            0.516828   \n",
       "288        0.001597               13            0.516828            0.516828   \n",
       "341        0.001597               13            0.516828            0.516828   \n",
       "55         0.001540               15            0.516828            0.516828   \n",
       "243        0.001470               15            0.516828            0.516828   \n",
       "336        0.001106               17            0.516828            0.516828   \n",
       "340        0.000799               18            0.516828            0.517185   \n",
       "339        0.000799               18            0.516828            0.523602   \n",
       "337        0.000513               20            0.516828            0.516828   \n",
       "298        0.000456               21            0.518361            0.516828   \n",
       "338        0.000228               22            0.517862            0.516828   \n",
       "344        0.000171               23            0.516828            0.516828   \n",
       "254        0.000000               24            0.516828            0.516828   \n",
       "248        0.000000               24            0.516828            0.516828   \n",
       "247        0.000000               24            0.516828            0.516828   \n",
       "245        0.000000               24            0.516828            0.516828   \n",
       "250        0.000000               24            0.516828            0.516828   \n",
       "251        0.000000               24            0.516828            0.516828   \n",
       "244        0.000000               24            0.516828            0.516828   \n",
       "..              ...              ...                 ...                 ...   \n",
       "104        0.000000               24            0.516828            0.516828   \n",
       "103        0.000000               24            0.516828            0.516828   \n",
       "102        0.000000               24            0.516828            0.516828   \n",
       "101        0.000000               24            0.516828            0.516828   \n",
       "121        0.000000               24            0.516828            0.516828   \n",
       "122        0.000000               24            0.516828            0.516828   \n",
       "123        0.000000               24            0.516828            0.516828   \n",
       "134        0.000000               24            0.516828            0.516828   \n",
       "143        0.000000               24            0.516828            0.516828   \n",
       "142        0.000000               24            0.516828            0.516828   \n",
       "141        0.000000               24            0.516828            0.516828   \n",
       "140        0.000000               24            0.516828            0.516828   \n",
       "139        0.000000               24            0.516828            0.516828   \n",
       "138        0.000000               24            0.516828            0.516828   \n",
       "137        0.000000               24            0.516828            0.516828   \n",
       "136        0.000000               24            0.516828            0.516828   \n",
       "124        0.000000               24            0.516828            0.516828   \n",
       "135        0.000000               24            0.516828            0.516828   \n",
       "133        0.000000               24            0.516828            0.516828   \n",
       "132        0.000000               24            0.516828            0.516828   \n",
       "131        0.000000               24            0.516828            0.516828   \n",
       "130        0.000000               24            0.516828            0.516828   \n",
       "129        0.000000               24            0.516828            0.516828   \n",
       "128        0.000000               24            0.516828            0.516828   \n",
       "127        0.000000               24            0.516828            0.516828   \n",
       "126        0.000000               24            0.516828            0.516828   \n",
       "125        0.000000               24            0.516828            0.516828   \n",
       "383        0.000000               24            0.516828            0.516828   \n",
       "296        0.000057              383            0.516828            0.516828   \n",
       "9          0.000342              384            0.516828            0.516828   \n",
       "\n",
       "     split2_train_score  split3_train_score  split4_train_score  \\\n",
       "105            0.516828            0.516828            0.527025   \n",
       "54             0.516828            0.529022            0.529770   \n",
       "297            0.516828            0.526954            0.516828   \n",
       "246            0.530020            0.531660            0.516828   \n",
       "342            0.516828            0.516900            0.516828   \n",
       "51             0.528059            0.516828            0.516828   \n",
       "289            0.516828            0.528416            0.516828   \n",
       "147            0.526847            0.516828            0.516828   \n",
       "291            0.516828            0.530448            0.516828   \n",
       "249            0.516828            0.516828            0.516828   \n",
       "345            0.530234            0.516828            0.516828   \n",
       "48             0.516828            0.531838            0.516828   \n",
       "288            0.530733            0.516864            0.516828   \n",
       "341            0.527203            0.516828            0.516828   \n",
       "55             0.530662            0.516828            0.516828   \n",
       "243            0.516828            0.516828            0.526383   \n",
       "336            0.527275            0.525278            0.516828   \n",
       "340            0.516828            0.518789            0.516828   \n",
       "339            0.516828            0.516828            0.516828   \n",
       "337            0.516828            0.517827            0.516828   \n",
       "298            0.516828            0.517042            0.516828   \n",
       "338            0.516828            0.516828            0.516828   \n",
       "344            0.516828            0.516828            0.517220   \n",
       "254            0.516828            0.516828            0.516828   \n",
       "248            0.516828            0.516828            0.516828   \n",
       "247            0.516828            0.516828            0.516828   \n",
       "245            0.516828            0.516828            0.516828   \n",
       "250            0.516828            0.516828            0.516828   \n",
       "251            0.516828            0.516828            0.516828   \n",
       "244            0.516828            0.516828            0.516828   \n",
       "..                  ...                 ...                 ...   \n",
       "104            0.516828            0.516828            0.516828   \n",
       "103            0.516828            0.516828            0.516828   \n",
       "102            0.516828            0.516828            0.516828   \n",
       "101            0.516828            0.516828            0.516828   \n",
       "121            0.516828            0.516828            0.516828   \n",
       "122            0.516828            0.516828            0.516828   \n",
       "123            0.516828            0.516828            0.516828   \n",
       "134            0.516828            0.516828            0.516828   \n",
       "143            0.516828            0.516828            0.516828   \n",
       "142            0.516828            0.516828            0.516828   \n",
       "141            0.516828            0.516828            0.516828   \n",
       "140            0.516828            0.516828            0.516828   \n",
       "139            0.516828            0.516828            0.516828   \n",
       "138            0.516828            0.516828            0.516828   \n",
       "137            0.516828            0.516828            0.516828   \n",
       "136            0.516828            0.516828            0.516828   \n",
       "124            0.516828            0.516828            0.516828   \n",
       "135            0.516828            0.516828            0.516828   \n",
       "133            0.516828            0.516828            0.516828   \n",
       "132            0.516828            0.516828            0.516828   \n",
       "131            0.516828            0.516828            0.516828   \n",
       "130            0.516828            0.516828            0.516828   \n",
       "129            0.516828            0.516828            0.516828   \n",
       "128            0.516828            0.516828            0.516828   \n",
       "127            0.516828            0.516828            0.516828   \n",
       "126            0.516828            0.516828            0.516828   \n",
       "125            0.516828            0.516828            0.516828   \n",
       "383            0.516828            0.516828            0.516828   \n",
       "296            0.517363            0.516828            0.516828   \n",
       "9              0.516828            0.527738            0.516828   \n",
       "\n",
       "     mean_train_score  std_train_score  \n",
       "105          0.520971         0.005075  \n",
       "54           0.521855         0.006161  \n",
       "297          0.521335         0.005566  \n",
       "246          0.522433         0.006884  \n",
       "342          0.519032         0.004371  \n",
       "51           0.519074         0.004492  \n",
       "289          0.519146         0.004635  \n",
       "147          0.518832         0.004007  \n",
       "291          0.519559         0.005444  \n",
       "249          0.519167         0.004678  \n",
       "345          0.519509         0.005362  \n",
       "48           0.519830         0.006004  \n",
       "288          0.519616         0.005558  \n",
       "341          0.518903         0.004150  \n",
       "55           0.519595         0.005533  \n",
       "243          0.518739         0.003822  \n",
       "336          0.520608         0.004671  \n",
       "340          0.517292         0.000761  \n",
       "339          0.518183         0.002710  \n",
       "337          0.517028         0.000399  \n",
       "298          0.517178         0.000598  \n",
       "338          0.517035         0.000414  \n",
       "344          0.516907         0.000157  \n",
       "254          0.516828         0.000000  \n",
       "248          0.516828         0.000000  \n",
       "247          0.516828         0.000000  \n",
       "245          0.516828         0.000000  \n",
       "250          0.516828         0.000000  \n",
       "251          0.516828         0.000000  \n",
       "244          0.516828         0.000000  \n",
       "..                ...              ...  \n",
       "104          0.516828         0.000000  \n",
       "103          0.516828         0.000000  \n",
       "102          0.516828         0.000000  \n",
       "101          0.516828         0.000000  \n",
       "121          0.516828         0.000000  \n",
       "122          0.516828         0.000000  \n",
       "123          0.516828         0.000000  \n",
       "134          0.516828         0.000000  \n",
       "143          0.516828         0.000000  \n",
       "142          0.516828         0.000000  \n",
       "141          0.516828         0.000000  \n",
       "140          0.516828         0.000000  \n",
       "139          0.516828         0.000000  \n",
       "138          0.516828         0.000000  \n",
       "137          0.516828         0.000000  \n",
       "136          0.516828         0.000000  \n",
       "124          0.516828         0.000000  \n",
       "135          0.516828         0.000000  \n",
       "133          0.516828         0.000000  \n",
       "132          0.516828         0.000000  \n",
       "131          0.516828         0.000000  \n",
       "130          0.516828         0.000000  \n",
       "129          0.516828         0.000000  \n",
       "128          0.516828         0.000000  \n",
       "127          0.516828         0.000000  \n",
       "126          0.516828         0.000000  \n",
       "125          0.516828         0.000000  \n",
       "383          0.516828         0.000000  \n",
       "296          0.516935         0.000214  \n",
       "9            0.519010         0.004364  \n",
       "\n",
       "[384 rows x 25 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_df.sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the parameters match the top line if we set the best mean_test_score to be on top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another way to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_df['difference'] = gs_df['mean_train_score'] - gs_df['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_impurity_decrease</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.309199</td>\n",
       "      <td>0.036454</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.527382</td>\n",
       "      <td>0.521763</td>\n",
       "      <td>0.006148</td>\n",
       "      <td>1</td>\n",
       "      <td>0.527025</td>\n",
       "      <td>0.520971</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>-0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0.509799</td>\n",
       "      <td>0.077281</td>\n",
       "      <td>0.012201</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516971</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519424</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519032</td>\n",
       "      <td>0.004371</td>\n",
       "      <td>-0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2.119398</td>\n",
       "      <td>0.085510</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518112</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517085</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>20</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517028</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>-0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>4.266597</td>\n",
       "      <td>0.354899</td>\n",
       "      <td>0.074601</td>\n",
       "      <td>0.008014</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517256</td>\n",
       "      <td>0.516914</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>23</td>\n",
       "      <td>0.517220</td>\n",
       "      <td>0.516907</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>-0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1.777398</td>\n",
       "      <td>0.066715</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>3.654998</td>\n",
       "      <td>0.073115</td>\n",
       "      <td>0.076001</td>\n",
       "      <td>0.006899</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1.838003</td>\n",
       "      <td>0.093359</td>\n",
       "      <td>0.037998</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>3.618598</td>\n",
       "      <td>0.101651</td>\n",
       "      <td>0.073204</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>1.774797</td>\n",
       "      <td>0.063039</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>3.830997</td>\n",
       "      <td>0.240630</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>1.858999</td>\n",
       "      <td>0.169797</td>\n",
       "      <td>0.035804</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.376398</td>\n",
       "      <td>0.034297</td>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.165006</td>\n",
       "      <td>0.010762</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>3.663796</td>\n",
       "      <td>0.170172</td>\n",
       "      <td>0.071601</td>\n",
       "      <td>0.007736</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1.305601</td>\n",
       "      <td>0.027506</td>\n",
       "      <td>0.036399</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.269000</td>\n",
       "      <td>0.019164</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2.547397</td>\n",
       "      <td>0.037909</td>\n",
       "      <td>0.065805</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>1.269999</td>\n",
       "      <td>0.051888</td>\n",
       "      <td>0.034601</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.264199</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.009801</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2.503795</td>\n",
       "      <td>0.037812</td>\n",
       "      <td>0.067201</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>1.277197</td>\n",
       "      <td>0.018488</td>\n",
       "      <td>0.034402</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2.486794</td>\n",
       "      <td>0.031271</td>\n",
       "      <td>0.063201</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.265398</td>\n",
       "      <td>0.011671</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1.275399</td>\n",
       "      <td>0.035053</td>\n",
       "      <td>0.034201</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2.831200</td>\n",
       "      <td>0.163244</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>1.304398</td>\n",
       "      <td>0.034920</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.275996</td>\n",
       "      <td>0.008785</td>\n",
       "      <td>0.010401</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>2.583796</td>\n",
       "      <td>0.088836</td>\n",
       "      <td>0.069199</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>1.442598</td>\n",
       "      <td>0.142260</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.020514</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.267396</td>\n",
       "      <td>0.009415</td>\n",
       "      <td>0.009601</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.205798</td>\n",
       "      <td>0.007439</td>\n",
       "      <td>0.014202</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.970398</td>\n",
       "      <td>0.025162</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.207398</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.256596</td>\n",
       "      <td>0.034172</td>\n",
       "      <td>0.011599</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1.998806</td>\n",
       "      <td>0.103331</td>\n",
       "      <td>0.071793</td>\n",
       "      <td>0.007562</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.212195</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.009602</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2.123600</td>\n",
       "      <td>0.223045</td>\n",
       "      <td>0.063598</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.041098</td>\n",
       "      <td>0.034598</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2.001200</td>\n",
       "      <td>0.131923</td>\n",
       "      <td>0.038598</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516857</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2.132798</td>\n",
       "      <td>0.190474</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518825</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517228</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>18</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517292</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.272396</td>\n",
       "      <td>0.023398</td>\n",
       "      <td>0.009399</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527667</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518996</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>6</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519074</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>4.163400</td>\n",
       "      <td>0.349124</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516942</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>22</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517035</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2.166600</td>\n",
       "      <td>0.165213</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517056</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>21</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517178</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>4.298598</td>\n",
       "      <td>0.537318</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516686</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516800</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>383</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516935</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.301597</td>\n",
       "      <td>0.025894</td>\n",
       "      <td>0.010202</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_im...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525670</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518597</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>8</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518832</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>2.194199</td>\n",
       "      <td>0.248337</td>\n",
       "      <td>0.036001</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.526811</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518825</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>7</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519146</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.439401</td>\n",
       "      <td>0.033704</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517228</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>18</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518183</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.000956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.379597</td>\n",
       "      <td>0.056790</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518026</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>10</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519167</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>0.001141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.445596</td>\n",
       "      <td>0.072297</td>\n",
       "      <td>0.012601</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.520536</td>\n",
       "      <td>0.517598</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>15</td>\n",
       "      <td>0.526383</td>\n",
       "      <td>0.518739</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.001141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>4.325398</td>\n",
       "      <td>0.556493</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520821</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517627</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>13</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518903</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.001276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.451798</td>\n",
       "      <td>0.091456</td>\n",
       "      <td>0.010199</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.526383</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519880</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>3</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.521335</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>0.001455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.462799</td>\n",
       "      <td>0.034395</td>\n",
       "      <td>0.011401</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.522818</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518055</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>9</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519559</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.001505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.276994</td>\n",
       "      <td>0.023886</td>\n",
       "      <td>0.009401</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.520679</td>\n",
       "      <td>0.529663</td>\n",
       "      <td>0.520165</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>2</td>\n",
       "      <td>0.529770</td>\n",
       "      <td>0.521855</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>0.001690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0.432797</td>\n",
       "      <td>0.060981</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521677</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517798</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>11</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519509</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.001711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.417799</td>\n",
       "      <td>0.041013</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520821</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517627</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>13</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519616</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.001989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.288013</td>\n",
       "      <td>0.027975</td>\n",
       "      <td>0.040385</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520679</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517598</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>15</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519595</td>\n",
       "      <td>0.005533</td>\n",
       "      <td>0.001997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.271398</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>0.009601</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.521249</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517712</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>12</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519830</td>\n",
       "      <td>0.006004</td>\n",
       "      <td>0.002118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.173003</td>\n",
       "      <td>0.009055</td>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.515973</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516657</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>384</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519010</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>0.002353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.397995</td>\n",
       "      <td>0.025966</td>\n",
       "      <td>0.010401</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526811</td>\n",
       "      <td>0.521677</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519795</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>4</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.522433</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>0.002638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.438998</td>\n",
       "      <td>0.068833</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519681</td>\n",
       "      <td>0.517684</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517570</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>17</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.520608</td>\n",
       "      <td>0.004671</td>\n",
       "      <td>0.003038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "105       0.309199      0.036454         0.010000        0.000002   \n",
       "342       0.509799      0.077281         0.012201        0.002040   \n",
       "337       2.119398      0.085510         0.035800        0.001327   \n",
       "344       4.266597      0.354899         0.074601        0.008014   \n",
       "250       1.777398      0.066715         0.038000        0.003742   \n",
       "248       3.654998      0.073115         0.076001        0.006899   \n",
       "247       1.838003      0.093359         0.037998        0.002272   \n",
       "245       3.618598      0.101651         0.073204        0.005075   \n",
       "244       1.774797      0.063039         0.038200        0.003869   \n",
       "242       3.830997      0.240630         0.069600        0.004317   \n",
       "241       1.858999      0.169797         0.035804        0.001720   \n",
       "240       0.376398      0.034297         0.010001        0.000634   \n",
       "0         0.165006      0.010762         0.014194        0.002387   \n",
       "251       3.663796      0.170172         0.071601        0.007736   \n",
       "238       1.305601      0.027506         0.036399        0.002060   \n",
       "237       0.269000      0.019164         0.009200        0.000749   \n",
       "236       2.547397      0.037909         0.065805        0.001945   \n",
       "235       1.269999      0.051888         0.034601        0.001625   \n",
       "234       0.264199      0.005776         0.009801        0.000749   \n",
       "233       2.503795      0.037812         0.067201        0.005034   \n",
       "232       1.277197      0.018488         0.034402        0.001356   \n",
       "239       2.486794      0.031271         0.063201        0.001166   \n",
       "252       0.265398      0.011671         0.008800        0.000399   \n",
       "253       1.275399      0.035053         0.034201        0.001469   \n",
       "254       2.831200      0.163244         0.069400        0.003498   \n",
       "274       1.304398      0.034920         0.034200        0.000749   \n",
       "273       0.275996      0.008785         0.010401        0.001498   \n",
       "272       2.583796      0.088836         0.069199        0.001600   \n",
       "271       1.442598      0.142260         0.043000        0.020514   \n",
       "270       0.267396      0.009415         0.009601        0.001021   \n",
       "..             ...           ...              ...             ...   \n",
       "129       0.205798      0.007439         0.014202        0.009926   \n",
       "130       0.970398      0.025162         0.035400        0.003320   \n",
       "126       0.207398      0.006946         0.009200        0.000401   \n",
       "123       0.256596      0.034172         0.011599        0.003666   \n",
       "131       1.998806      0.103331         0.071793        0.007562   \n",
       "132       0.212195      0.016905         0.009602        0.000800   \n",
       "122       2.123600      0.223045         0.063598        0.002579   \n",
       "124       0.987000      0.041098         0.034598        0.001959   \n",
       "295       2.001200      0.131923         0.038598        0.002243   \n",
       "340       2.132798      0.190474         0.036200        0.001470   \n",
       "51        0.272396      0.023398         0.009399        0.000488   \n",
       "338       4.163400      0.349124         0.071200        0.004708   \n",
       "298       2.166600      0.165213         0.041200        0.009108   \n",
       "296       4.298598      0.537318         0.071800        0.005307   \n",
       "147       0.301597      0.025894         0.010202        0.000401   \n",
       "289       2.194199      0.248337         0.036001        0.001414   \n",
       "339       0.439401      0.033704         0.009397        0.000802   \n",
       "249       0.379597      0.056790         0.009600        0.000490   \n",
       "243       0.445596      0.072297         0.012601        0.005713   \n",
       "341       4.325398      0.556493         0.070200        0.004491   \n",
       "297       0.451798      0.091456         0.010199        0.000401   \n",
       "291       0.462799      0.034395         0.011401        0.002061   \n",
       "54        0.276994      0.023886         0.009401        0.000800   \n",
       "345       0.432797      0.060981         0.009599        0.000492   \n",
       "288       0.417799      0.041013         0.010400        0.000801   \n",
       "55        1.288013      0.027975         0.040385        0.005824   \n",
       "48        0.271398      0.006917         0.009601        0.000801   \n",
       "9         0.173003      0.009055         0.007597        0.000486   \n",
       "246       0.397995      0.025966         0.010401        0.001201   \n",
       "336       0.438998      0.068833         0.009202        0.000398   \n",
       "\n",
       "    param_criterion param_max_depth param_min_impurity_decrease  \\\n",
       "105            gini               5                       0.001   \n",
       "342         entropy              10                       0.001   \n",
       "337         entropy              10                       0.001   \n",
       "344         entropy              10                       0.001   \n",
       "250         entropy               2                       0.001   \n",
       "248         entropy               2                       0.001   \n",
       "247         entropy               2                       0.001   \n",
       "245         entropy               2                       0.001   \n",
       "244         entropy               2                       0.001   \n",
       "242         entropy               2                       0.001   \n",
       "241         entropy               2                       0.001   \n",
       "240         entropy               2                       0.001   \n",
       "0              gini               1                       0.001   \n",
       "251         entropy               2                       0.001   \n",
       "238         entropy               1                        0.15   \n",
       "237         entropy               1                        0.15   \n",
       "236         entropy               1                        0.15   \n",
       "235         entropy               1                        0.15   \n",
       "234         entropy               1                        0.15   \n",
       "233         entropy               1                        0.15   \n",
       "232         entropy               1                        0.15   \n",
       "239         entropy               1                        0.15   \n",
       "252         entropy               2                        0.01   \n",
       "253         entropy               2                        0.01   \n",
       "254         entropy               2                        0.01   \n",
       "274         entropy               2                         0.1   \n",
       "273         entropy               2                         0.1   \n",
       "272         entropy               2                         0.1   \n",
       "271         entropy               2                         0.1   \n",
       "270         entropy               2                         0.1   \n",
       "..              ...             ...                         ...   \n",
       "129            gini               5                         0.1   \n",
       "130            gini               5                         0.1   \n",
       "126            gini               5                         0.1   \n",
       "123            gini               5                         0.1   \n",
       "131            gini               5                         0.1   \n",
       "132            gini               5                        0.15   \n",
       "122            gini               5                         0.1   \n",
       "124            gini               5                         0.1   \n",
       "295         entropy               5                       0.001   \n",
       "340         entropy              10                       0.001   \n",
       "51             gini               2                       0.001   \n",
       "338         entropy              10                       0.001   \n",
       "298         entropy               5                       0.001   \n",
       "296         entropy               5                       0.001   \n",
       "147            gini              10                       0.001   \n",
       "289         entropy               5                       0.001   \n",
       "339         entropy              10                       0.001   \n",
       "249         entropy               2                       0.001   \n",
       "243         entropy               2                       0.001   \n",
       "341         entropy              10                       0.001   \n",
       "297         entropy               5                       0.001   \n",
       "291         entropy               5                       0.001   \n",
       "54             gini               2                       0.001   \n",
       "345         entropy              10                       0.001   \n",
       "288         entropy               5                       0.001   \n",
       "55             gini               2                       0.001   \n",
       "48             gini               2                       0.001   \n",
       "9              gini               1                       0.001   \n",
       "246         entropy               2                       0.001   \n",
       "336         entropy              10                       0.001   \n",
       "\n",
       "    param_min_samples_leaf param_n_estimators  \\\n",
       "105                     25                 10   \n",
       "342                     20                 10   \n",
       "337                     10                 50   \n",
       "344                     20                100   \n",
       "250                     25                 50   \n",
       "248                     20                100   \n",
       "247                     20                 50   \n",
       "245                     15                100   \n",
       "244                     15                 50   \n",
       "242                     10                100   \n",
       "241                     10                 50   \n",
       "240                     10                 10   \n",
       "0                       10                 10   \n",
       "251                     25                100   \n",
       "238                     25                 50   \n",
       "237                     25                 10   \n",
       "236                     20                100   \n",
       "235                     20                 50   \n",
       "234                     20                 10   \n",
       "233                     15                100   \n",
       "232                     15                 50   \n",
       "239                     25                100   \n",
       "252                     10                 10   \n",
       "253                     10                 50   \n",
       "254                     10                100   \n",
       "274                     25                 50   \n",
       "273                     25                 10   \n",
       "272                     20                100   \n",
       "271                     20                 50   \n",
       "270                     20                 10   \n",
       "..                     ...                ...   \n",
       "129                     25                 10   \n",
       "130                     25                 50   \n",
       "126                     20                 10   \n",
       "123                     15                 10   \n",
       "131                     25                100   \n",
       "132                     10                 10   \n",
       "122                     10                100   \n",
       "124                     15                 50   \n",
       "295                     20                 50   \n",
       "340                     15                 50   \n",
       "51                      15                 10   \n",
       "338                     10                100   \n",
       "298                     25                 50   \n",
       "296                     20                100   \n",
       "147                     15                 10   \n",
       "289                     10                 50   \n",
       "339                     15                 10   \n",
       "249                     25                 10   \n",
       "243                     15                 10   \n",
       "341                     15                100   \n",
       "297                     25                 10   \n",
       "291                     15                 10   \n",
       "54                      20                 10   \n",
       "345                     25                 10   \n",
       "288                     10                 10   \n",
       "55                      20                 50   \n",
       "48                      10                 10   \n",
       "9                       25                 10   \n",
       "246                     20                 10   \n",
       "336                     10                 10   \n",
       "\n",
       "                                                params  ...  \\\n",
       "105  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "342  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "337  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "344  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "250  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "248  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "247  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "245  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "244  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "242  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "241  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "240  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "0    {'criterion': 'gini', 'max_depth': 1, 'min_imp...  ...   \n",
       "251  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "238  {'criterion': 'entropy', 'max_depth': 1, 'min_...  ...   \n",
       "237  {'criterion': 'entropy', 'max_depth': 1, 'min_...  ...   \n",
       "236  {'criterion': 'entropy', 'max_depth': 1, 'min_...  ...   \n",
       "235  {'criterion': 'entropy', 'max_depth': 1, 'min_...  ...   \n",
       "234  {'criterion': 'entropy', 'max_depth': 1, 'min_...  ...   \n",
       "233  {'criterion': 'entropy', 'max_depth': 1, 'min_...  ...   \n",
       "232  {'criterion': 'entropy', 'max_depth': 1, 'min_...  ...   \n",
       "239  {'criterion': 'entropy', 'max_depth': 1, 'min_...  ...   \n",
       "252  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "253  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "254  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "274  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "273  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "272  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "271  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "270  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "..                                                 ...  ...   \n",
       "129  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "130  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "126  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "123  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "131  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "132  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "122  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "124  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "295  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...   \n",
       "340  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "51   {'criterion': 'gini', 'max_depth': 2, 'min_imp...  ...   \n",
       "338  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "298  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...   \n",
       "296  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...   \n",
       "147  {'criterion': 'gini', 'max_depth': 10, 'min_im...  ...   \n",
       "289  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...   \n",
       "339  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "249  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "243  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "341  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "297  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...   \n",
       "291  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...   \n",
       "54   {'criterion': 'gini', 'max_depth': 2, 'min_imp...  ...   \n",
       "345  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "288  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...   \n",
       "55   {'criterion': 'gini', 'max_depth': 2, 'min_imp...  ...   \n",
       "48   {'criterion': 'gini', 'max_depth': 2, 'min_imp...  ...   \n",
       "9    {'criterion': 'gini', 'max_depth': 1, 'min_imp...  ...   \n",
       "246  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "336  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "\n",
       "     split2_test_score  split3_test_score  split4_test_score  mean_test_score  \\\n",
       "105           0.516828           0.516828           0.527382         0.521763   \n",
       "342           0.516828           0.516971           0.516828         0.519424   \n",
       "337           0.516828           0.518112           0.516828         0.517085   \n",
       "344           0.516828           0.516828           0.517256         0.516914   \n",
       "250           0.516828           0.516828           0.516828         0.516828   \n",
       "248           0.516828           0.516828           0.516828         0.516828   \n",
       "247           0.516828           0.516828           0.516828         0.516828   \n",
       "245           0.516828           0.516828           0.516828         0.516828   \n",
       "244           0.516828           0.516828           0.516828         0.516828   \n",
       "242           0.516828           0.516828           0.516828         0.516828   \n",
       "241           0.516828           0.516828           0.516828         0.516828   \n",
       "240           0.516828           0.516828           0.516828         0.516828   \n",
       "0             0.516828           0.516828           0.516828         0.516828   \n",
       "251           0.516828           0.516828           0.516828         0.516828   \n",
       "238           0.516828           0.516828           0.516828         0.516828   \n",
       "237           0.516828           0.516828           0.516828         0.516828   \n",
       "236           0.516828           0.516828           0.516828         0.516828   \n",
       "235           0.516828           0.516828           0.516828         0.516828   \n",
       "234           0.516828           0.516828           0.516828         0.516828   \n",
       "233           0.516828           0.516828           0.516828         0.516828   \n",
       "232           0.516828           0.516828           0.516828         0.516828   \n",
       "239           0.516828           0.516828           0.516828         0.516828   \n",
       "252           0.516828           0.516828           0.516828         0.516828   \n",
       "253           0.516828           0.516828           0.516828         0.516828   \n",
       "254           0.516828           0.516828           0.516828         0.516828   \n",
       "274           0.516828           0.516828           0.516828         0.516828   \n",
       "273           0.516828           0.516828           0.516828         0.516828   \n",
       "272           0.516828           0.516828           0.516828         0.516828   \n",
       "271           0.516828           0.516828           0.516828         0.516828   \n",
       "270           0.516828           0.516828           0.516828         0.516828   \n",
       "..                 ...                ...                ...              ...   \n",
       "129           0.516828           0.516828           0.516828         0.516828   \n",
       "130           0.516828           0.516828           0.516828         0.516828   \n",
       "126           0.516828           0.516828           0.516828         0.516828   \n",
       "123           0.516828           0.516828           0.516828         0.516828   \n",
       "131           0.516828           0.516828           0.516828         0.516828   \n",
       "132           0.516828           0.516828           0.516828         0.516828   \n",
       "122           0.516828           0.516828           0.516828         0.516828   \n",
       "124           0.516828           0.516828           0.516828         0.516828   \n",
       "295           0.516828           0.516828           0.516828         0.516828   \n",
       "340           0.516828           0.518825           0.516828         0.517228   \n",
       "51            0.527667           0.516828           0.516828         0.518996   \n",
       "338           0.516828           0.516828           0.516828         0.516942   \n",
       "298           0.516828           0.516828           0.516828         0.517056   \n",
       "296           0.516686           0.516828           0.516828         0.516800   \n",
       "147           0.525670           0.516828           0.516828         0.518597   \n",
       "289           0.516828           0.526811           0.516828         0.518825   \n",
       "339           0.516828           0.516828           0.516828         0.517228   \n",
       "249           0.516828           0.516828           0.516828         0.518026   \n",
       "243           0.516828           0.516828           0.520536         0.517598   \n",
       "341           0.520821           0.516828           0.516828         0.517627   \n",
       "297           0.516828           0.526383           0.516828         0.519880   \n",
       "291           0.516828           0.522818           0.516828         0.518055   \n",
       "54            0.516828           0.520679           0.529663         0.520165   \n",
       "345           0.521677           0.516828           0.516828         0.517798   \n",
       "288           0.520821           0.516828           0.516828         0.517627   \n",
       "55            0.520679           0.516828           0.516828         0.517598   \n",
       "48            0.516828           0.521249           0.516828         0.517712   \n",
       "9             0.516828           0.515973           0.516828         0.516657   \n",
       "246           0.526811           0.521677           0.516828         0.519795   \n",
       "336           0.519681           0.517684           0.516828         0.517570   \n",
       "\n",
       "     std_test_score  rank_test_score  split4_train_score  mean_train_score  \\\n",
       "105        0.006148                1            0.527025          0.520971   \n",
       "342        0.005120                5            0.516828          0.519032   \n",
       "337        0.000513               20            0.516828          0.517028   \n",
       "344        0.000171               23            0.517220          0.516907   \n",
       "250        0.000000               24            0.516828          0.516828   \n",
       "248        0.000000               24            0.516828          0.516828   \n",
       "247        0.000000               24            0.516828          0.516828   \n",
       "245        0.000000               24            0.516828          0.516828   \n",
       "244        0.000000               24            0.516828          0.516828   \n",
       "242        0.000000               24            0.516828          0.516828   \n",
       "241        0.000000               24            0.516828          0.516828   \n",
       "240        0.000000               24            0.516828          0.516828   \n",
       "0          0.000000               24            0.516828          0.516828   \n",
       "251        0.000000               24            0.516828          0.516828   \n",
       "238        0.000000               24            0.516828          0.516828   \n",
       "237        0.000000               24            0.516828          0.516828   \n",
       "236        0.000000               24            0.516828          0.516828   \n",
       "235        0.000000               24            0.516828          0.516828   \n",
       "234        0.000000               24            0.516828          0.516828   \n",
       "233        0.000000               24            0.516828          0.516828   \n",
       "232        0.000000               24            0.516828          0.516828   \n",
       "239        0.000000               24            0.516828          0.516828   \n",
       "252        0.000000               24            0.516828          0.516828   \n",
       "253        0.000000               24            0.516828          0.516828   \n",
       "254        0.000000               24            0.516828          0.516828   \n",
       "274        0.000000               24            0.516828          0.516828   \n",
       "273        0.000000               24            0.516828          0.516828   \n",
       "272        0.000000               24            0.516828          0.516828   \n",
       "271        0.000000               24            0.516828          0.516828   \n",
       "270        0.000000               24            0.516828          0.516828   \n",
       "..              ...              ...                 ...               ...   \n",
       "129        0.000000               24            0.516828          0.516828   \n",
       "130        0.000000               24            0.516828          0.516828   \n",
       "126        0.000000               24            0.516828          0.516828   \n",
       "123        0.000000               24            0.516828          0.516828   \n",
       "131        0.000000               24            0.516828          0.516828   \n",
       "132        0.000000               24            0.516828          0.516828   \n",
       "122        0.000000               24            0.516828          0.516828   \n",
       "124        0.000000               24            0.516828          0.516828   \n",
       "295        0.000000               24            0.516828          0.516857   \n",
       "340        0.000799               18            0.516828          0.517292   \n",
       "51         0.004335                6            0.516828          0.519074   \n",
       "338        0.000228               22            0.516828          0.517035   \n",
       "298        0.000456               21            0.516828          0.517178   \n",
       "296        0.000057              383            0.516828          0.516935   \n",
       "147        0.003537                8            0.516828          0.518832   \n",
       "289        0.003993                7            0.516828          0.519146   \n",
       "339        0.000799               18            0.516828          0.518183   \n",
       "249        0.002396               10            0.516828          0.519167   \n",
       "243        0.001470               15            0.526383          0.518739   \n",
       "341        0.001597               13            0.516828          0.518903   \n",
       "297        0.003931                3            0.516828          0.521335   \n",
       "291        0.002382                9            0.516828          0.519559   \n",
       "54         0.004978                2            0.529770          0.521855   \n",
       "345        0.001940               11            0.516828          0.519509   \n",
       "288        0.001597               13            0.516828          0.519616   \n",
       "55         0.001540               15            0.516828          0.519595   \n",
       "48         0.001768               12            0.516828          0.519830   \n",
       "9          0.000342              384            0.516828          0.519010   \n",
       "246        0.003979                4            0.516828          0.522433   \n",
       "336        0.001106               17            0.516828          0.520608   \n",
       "\n",
       "     std_train_score  difference  \n",
       "105         0.005075   -0.000792  \n",
       "342         0.004371   -0.000392  \n",
       "337         0.000399   -0.000057  \n",
       "344         0.000157   -0.000007  \n",
       "250         0.000000    0.000000  \n",
       "248         0.000000    0.000000  \n",
       "247         0.000000    0.000000  \n",
       "245         0.000000    0.000000  \n",
       "244         0.000000    0.000000  \n",
       "242         0.000000    0.000000  \n",
       "241         0.000000    0.000000  \n",
       "240         0.000000    0.000000  \n",
       "0           0.000000    0.000000  \n",
       "251         0.000000    0.000000  \n",
       "238         0.000000    0.000000  \n",
       "237         0.000000    0.000000  \n",
       "236         0.000000    0.000000  \n",
       "235         0.000000    0.000000  \n",
       "234         0.000000    0.000000  \n",
       "233         0.000000    0.000000  \n",
       "232         0.000000    0.000000  \n",
       "239         0.000000    0.000000  \n",
       "252         0.000000    0.000000  \n",
       "253         0.000000    0.000000  \n",
       "254         0.000000    0.000000  \n",
       "274         0.000000    0.000000  \n",
       "273         0.000000    0.000000  \n",
       "272         0.000000    0.000000  \n",
       "271         0.000000    0.000000  \n",
       "270         0.000000    0.000000  \n",
       "..               ...         ...  \n",
       "129         0.000000    0.000000  \n",
       "130         0.000000    0.000000  \n",
       "126         0.000000    0.000000  \n",
       "123         0.000000    0.000000  \n",
       "131         0.000000    0.000000  \n",
       "132         0.000000    0.000000  \n",
       "122         0.000000    0.000000  \n",
       "124         0.000000    0.000000  \n",
       "295         0.000057    0.000029  \n",
       "340         0.000761    0.000064  \n",
       "51          0.004492    0.000078  \n",
       "338         0.000414    0.000093  \n",
       "298         0.000598    0.000121  \n",
       "296         0.000214    0.000135  \n",
       "147         0.004007    0.000235  \n",
       "289         0.004635    0.000321  \n",
       "339         0.002710    0.000956  \n",
       "249         0.004678    0.001141  \n",
       "243         0.003822    0.001141  \n",
       "341         0.004150    0.001276  \n",
       "297         0.005566    0.001455  \n",
       "291         0.005444    0.001505  \n",
       "54          0.006161    0.001690  \n",
       "345         0.005362    0.001711  \n",
       "288         0.005558    0.001989  \n",
       "55          0.005533    0.001997  \n",
       "48          0.006004    0.002118  \n",
       "9           0.004364    0.002353  \n",
       "246         0.006884    0.002638  \n",
       "336         0.004671    0.003038  \n",
       "\n",
       "[384 rows x 22 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_df.drop(['split0_train_score', 'split1_train_score', 'split2_train_score', 'split3_train_score'], axis=1).sort_values(by='difference').loc[gs_df['mean_test_score']>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing we can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_df['weighted_test_score'] = gs_df['mean_test_score'] - gs_df['difference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_impurity_decrease</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>difference</th>\n",
       "      <th>weighted_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.309199</td>\n",
       "      <td>0.036454</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.527382</td>\n",
       "      <td>0.521763</td>\n",
       "      <td>0.006148</td>\n",
       "      <td>1</td>\n",
       "      <td>0.527025</td>\n",
       "      <td>0.520971</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>-0.000792</td>\n",
       "      <td>0.522554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0.509799</td>\n",
       "      <td>0.077281</td>\n",
       "      <td>0.012201</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516971</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519424</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519032</td>\n",
       "      <td>0.004371</td>\n",
       "      <td>-0.000392</td>\n",
       "      <td>0.519816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.272396</td>\n",
       "      <td>0.023398</td>\n",
       "      <td>0.009399</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518996</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>6</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519074</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.518918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>2.194199</td>\n",
       "      <td>0.248337</td>\n",
       "      <td>0.036001</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526811</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518825</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>7</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519146</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.518504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.276994</td>\n",
       "      <td>0.023886</td>\n",
       "      <td>0.009401</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520679</td>\n",
       "      <td>0.529663</td>\n",
       "      <td>0.520165</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>2</td>\n",
       "      <td>0.529770</td>\n",
       "      <td>0.521855</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.518475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.451798</td>\n",
       "      <td>0.091456</td>\n",
       "      <td>0.010199</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526383</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519880</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>3</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.521335</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.518426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.301597</td>\n",
       "      <td>0.025894</td>\n",
       "      <td>0.010202</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_im...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518597</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>8</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518832</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.518361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2.132798</td>\n",
       "      <td>0.190474</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518825</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517228</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>18</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517292</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.517163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.397995</td>\n",
       "      <td>0.025966</td>\n",
       "      <td>0.010401</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521677</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519795</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>4</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.522433</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>0.517156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2.119398</td>\n",
       "      <td>0.085510</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518112</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517085</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>20</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517028</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>0.517142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2.166600</td>\n",
       "      <td>0.165213</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517056</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>21</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517178</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.516935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>4.266597</td>\n",
       "      <td>0.354899</td>\n",
       "      <td>0.074601</td>\n",
       "      <td>0.008014</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517256</td>\n",
       "      <td>0.516914</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>23</td>\n",
       "      <td>0.517220</td>\n",
       "      <td>0.516907</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.516921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.379597</td>\n",
       "      <td>0.056790</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518026</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>10</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519167</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.516885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>4.163400</td>\n",
       "      <td>0.349124</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516942</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>22</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517035</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.516850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2.486794</td>\n",
       "      <td>0.031271</td>\n",
       "      <td>0.063201</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>3.618598</td>\n",
       "      <td>0.101651</td>\n",
       "      <td>0.073204</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>3.663796</td>\n",
       "      <td>0.170172</td>\n",
       "      <td>0.071601</td>\n",
       "      <td>0.007736</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1.777398</td>\n",
       "      <td>0.066715</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>3.654998</td>\n",
       "      <td>0.073115</td>\n",
       "      <td>0.076001</td>\n",
       "      <td>0.006899</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1.838003</td>\n",
       "      <td>0.093359</td>\n",
       "      <td>0.037998</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>3.830997</td>\n",
       "      <td>0.240630</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>1.774797</td>\n",
       "      <td>0.063039</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.269000</td>\n",
       "      <td>0.019164</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1.275399</td>\n",
       "      <td>0.035053</td>\n",
       "      <td>0.034201</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>1.858999</td>\n",
       "      <td>0.169797</td>\n",
       "      <td>0.035804</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1.305601</td>\n",
       "      <td>0.027506</td>\n",
       "      <td>0.036399</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.376398</td>\n",
       "      <td>0.034297</td>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.265398</td>\n",
       "      <td>0.011671</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.165006</td>\n",
       "      <td>0.010762</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2.831200</td>\n",
       "      <td>0.163244</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.217598</td>\n",
       "      <td>0.009851</td>\n",
       "      <td>0.009601</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.256596</td>\n",
       "      <td>0.034172</td>\n",
       "      <td>0.011599</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.212195</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.009602</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.236796</td>\n",
       "      <td>0.027811</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2.166600</td>\n",
       "      <td>0.202731</td>\n",
       "      <td>0.067799</td>\n",
       "      <td>0.005877</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.995999</td>\n",
       "      <td>0.030789</td>\n",
       "      <td>0.040002</td>\n",
       "      <td>0.006419</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.209197</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.041098</td>\n",
       "      <td>0.034598</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1.952402</td>\n",
       "      <td>0.014304</td>\n",
       "      <td>0.069999</td>\n",
       "      <td>0.006133</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.961196</td>\n",
       "      <td>0.016435</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2.297397</td>\n",
       "      <td>0.035307</td>\n",
       "      <td>0.050216</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1.998806</td>\n",
       "      <td>0.103331</td>\n",
       "      <td>0.071793</td>\n",
       "      <td>0.007562</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.970398</td>\n",
       "      <td>0.025162</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.205798</td>\n",
       "      <td>0.007439</td>\n",
       "      <td>0.014202</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.973199</td>\n",
       "      <td>0.026603</td>\n",
       "      <td>0.068601</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1.937798</td>\n",
       "      <td>0.034734</td>\n",
       "      <td>0.067399</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.954998</td>\n",
       "      <td>0.035951</td>\n",
       "      <td>0.036001</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.207398</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2.001200</td>\n",
       "      <td>0.131923</td>\n",
       "      <td>0.038598</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516857</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.516800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>4.298598</td>\n",
       "      <td>0.537318</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516800</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>383</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516935</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.516664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.462799</td>\n",
       "      <td>0.034395</td>\n",
       "      <td>0.011401</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522818</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518055</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>9</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519559</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.516550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.445596</td>\n",
       "      <td>0.072297</td>\n",
       "      <td>0.012601</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.520536</td>\n",
       "      <td>0.517598</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>15</td>\n",
       "      <td>0.526383</td>\n",
       "      <td>0.518739</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.516458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>4.325398</td>\n",
       "      <td>0.556493</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517627</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>13</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518903</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.516351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.439401</td>\n",
       "      <td>0.033704</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517228</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>18</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.518183</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.516272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0.432797</td>\n",
       "      <td>0.060981</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517798</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>11</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519509</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.516087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.417799</td>\n",
       "      <td>0.041013</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517627</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>13</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519616</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.515637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.288013</td>\n",
       "      <td>0.027975</td>\n",
       "      <td>0.040385</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517598</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>15</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519595</td>\n",
       "      <td>0.005533</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.515602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.271398</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>0.009601</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521249</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517712</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>12</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519830</td>\n",
       "      <td>0.006004</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.515595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.438998</td>\n",
       "      <td>0.068833</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517684</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.517570</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>17</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.520608</td>\n",
       "      <td>0.004671</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>0.514532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.173003</td>\n",
       "      <td>0.009055</td>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515973</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516657</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>384</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.519010</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.514304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "105       0.309199      0.036454         0.010000        0.000002   \n",
       "342       0.509799      0.077281         0.012201        0.002040   \n",
       "51        0.272396      0.023398         0.009399        0.000488   \n",
       "289       2.194199      0.248337         0.036001        0.001414   \n",
       "54        0.276994      0.023886         0.009401        0.000800   \n",
       "297       0.451798      0.091456         0.010199        0.000401   \n",
       "147       0.301597      0.025894         0.010202        0.000401   \n",
       "340       2.132798      0.190474         0.036200        0.001470   \n",
       "246       0.397995      0.025966         0.010401        0.001201   \n",
       "337       2.119398      0.085510         0.035800        0.001327   \n",
       "298       2.166600      0.165213         0.041200        0.009108   \n",
       "344       4.266597      0.354899         0.074601        0.008014   \n",
       "249       0.379597      0.056790         0.009600        0.000490   \n",
       "338       4.163400      0.349124         0.071200        0.004708   \n",
       "239       2.486794      0.031271         0.063201        0.001166   \n",
       "245       3.618598      0.101651         0.073204        0.005075   \n",
       "251       3.663796      0.170172         0.071601        0.007736   \n",
       "250       1.777398      0.066715         0.038000        0.003742   \n",
       "248       3.654998      0.073115         0.076001        0.006899   \n",
       "247       1.838003      0.093359         0.037998        0.002272   \n",
       "242       3.830997      0.240630         0.069600        0.004317   \n",
       "244       1.774797      0.063039         0.038200        0.003869   \n",
       "237       0.269000      0.019164         0.009200        0.000749   \n",
       "253       1.275399      0.035053         0.034201        0.001469   \n",
       "241       1.858999      0.169797         0.035804        0.001720   \n",
       "238       1.305601      0.027506         0.036399        0.002060   \n",
       "240       0.376398      0.034297         0.010001        0.000634   \n",
       "252       0.265398      0.011671         0.008800        0.000399   \n",
       "0         0.165006      0.010762         0.014194        0.002387   \n",
       "254       2.831200      0.163244         0.069400        0.003498   \n",
       "..             ...           ...              ...             ...   \n",
       "120       0.217598      0.009851         0.009601        0.000490   \n",
       "123       0.256596      0.034172         0.011599        0.003666   \n",
       "132       0.212195      0.016905         0.009602        0.000800   \n",
       "138       0.236796      0.027811         0.012000        0.003795   \n",
       "137       2.166600      0.202731         0.067799        0.005877   \n",
       "136       0.995999      0.030789         0.040002        0.006419   \n",
       "135       0.209197      0.004836         0.009002        0.000632   \n",
       "124       0.987000      0.041098         0.034598        0.001959   \n",
       "134       1.952402      0.014304         0.069999        0.006133   \n",
       "133       0.961196      0.016435         0.035400        0.001626   \n",
       "383       2.297397      0.035307         0.050216        0.004412   \n",
       "131       1.998806      0.103331         0.071793        0.007562   \n",
       "130       0.970398      0.025162         0.035400        0.003320   \n",
       "129       0.205798      0.007439         0.014202        0.009926   \n",
       "128       1.973199      0.026603         0.068601        0.005783   \n",
       "125       1.937798      0.034734         0.067399        0.002870   \n",
       "127       0.954998      0.035951         0.036001        0.003347   \n",
       "126       0.207398      0.006946         0.009200        0.000401   \n",
       "295       2.001200      0.131923         0.038598        0.002243   \n",
       "296       4.298598      0.537318         0.071800        0.005307   \n",
       "291       0.462799      0.034395         0.011401        0.002061   \n",
       "243       0.445596      0.072297         0.012601        0.005713   \n",
       "341       4.325398      0.556493         0.070200        0.004491   \n",
       "339       0.439401      0.033704         0.009397        0.000802   \n",
       "345       0.432797      0.060981         0.009599        0.000492   \n",
       "288       0.417799      0.041013         0.010400        0.000801   \n",
       "55        1.288013      0.027975         0.040385        0.005824   \n",
       "48        0.271398      0.006917         0.009601        0.000801   \n",
       "336       0.438998      0.068833         0.009202        0.000398   \n",
       "9         0.173003      0.009055         0.007597        0.000486   \n",
       "\n",
       "    param_criterion param_max_depth param_min_impurity_decrease  \\\n",
       "105            gini               5                       0.001   \n",
       "342         entropy              10                       0.001   \n",
       "51             gini               2                       0.001   \n",
       "289         entropy               5                       0.001   \n",
       "54             gini               2                       0.001   \n",
       "297         entropy               5                       0.001   \n",
       "147            gini              10                       0.001   \n",
       "340         entropy              10                       0.001   \n",
       "246         entropy               2                       0.001   \n",
       "337         entropy              10                       0.001   \n",
       "298         entropy               5                       0.001   \n",
       "344         entropy              10                       0.001   \n",
       "249         entropy               2                       0.001   \n",
       "338         entropy              10                       0.001   \n",
       "239         entropy               1                        0.15   \n",
       "245         entropy               2                       0.001   \n",
       "251         entropy               2                       0.001   \n",
       "250         entropy               2                       0.001   \n",
       "248         entropy               2                       0.001   \n",
       "247         entropy               2                       0.001   \n",
       "242         entropy               2                       0.001   \n",
       "244         entropy               2                       0.001   \n",
       "237         entropy               1                        0.15   \n",
       "253         entropy               2                        0.01   \n",
       "241         entropy               2                       0.001   \n",
       "238         entropy               1                        0.15   \n",
       "240         entropy               2                       0.001   \n",
       "252         entropy               2                        0.01   \n",
       "0              gini               1                       0.001   \n",
       "254         entropy               2                        0.01   \n",
       "..              ...             ...                         ...   \n",
       "120            gini               5                         0.1   \n",
       "123            gini               5                         0.1   \n",
       "132            gini               5                        0.15   \n",
       "138            gini               5                        0.15   \n",
       "137            gini               5                        0.15   \n",
       "136            gini               5                        0.15   \n",
       "135            gini               5                        0.15   \n",
       "124            gini               5                         0.1   \n",
       "134            gini               5                        0.15   \n",
       "133            gini               5                        0.15   \n",
       "383         entropy              10                        0.15   \n",
       "131            gini               5                         0.1   \n",
       "130            gini               5                         0.1   \n",
       "129            gini               5                         0.1   \n",
       "128            gini               5                         0.1   \n",
       "125            gini               5                         0.1   \n",
       "127            gini               5                         0.1   \n",
       "126            gini               5                         0.1   \n",
       "295         entropy               5                       0.001   \n",
       "296         entropy               5                       0.001   \n",
       "291         entropy               5                       0.001   \n",
       "243         entropy               2                       0.001   \n",
       "341         entropy              10                       0.001   \n",
       "339         entropy              10                       0.001   \n",
       "345         entropy              10                       0.001   \n",
       "288         entropy               5                       0.001   \n",
       "55             gini               2                       0.001   \n",
       "48             gini               2                       0.001   \n",
       "336         entropy              10                       0.001   \n",
       "9              gini               1                       0.001   \n",
       "\n",
       "    param_min_samples_leaf param_n_estimators  \\\n",
       "105                     25                 10   \n",
       "342                     20                 10   \n",
       "51                      15                 10   \n",
       "289                     10                 50   \n",
       "54                      20                 10   \n",
       "297                     25                 10   \n",
       "147                     15                 10   \n",
       "340                     15                 50   \n",
       "246                     20                 10   \n",
       "337                     10                 50   \n",
       "298                     25                 50   \n",
       "344                     20                100   \n",
       "249                     25                 10   \n",
       "338                     10                100   \n",
       "239                     25                100   \n",
       "245                     15                100   \n",
       "251                     25                100   \n",
       "250                     25                 50   \n",
       "248                     20                100   \n",
       "247                     20                 50   \n",
       "242                     10                100   \n",
       "244                     15                 50   \n",
       "237                     25                 10   \n",
       "253                     10                 50   \n",
       "241                     10                 50   \n",
       "238                     25                 50   \n",
       "240                     10                 10   \n",
       "252                     10                 10   \n",
       "0                       10                 10   \n",
       "254                     10                100   \n",
       "..                     ...                ...   \n",
       "120                     10                 10   \n",
       "123                     15                 10   \n",
       "132                     10                 10   \n",
       "138                     20                 10   \n",
       "137                     15                100   \n",
       "136                     15                 50   \n",
       "135                     15                 10   \n",
       "124                     15                 50   \n",
       "134                     10                100   \n",
       "133                     10                 50   \n",
       "383                     25                100   \n",
       "131                     25                100   \n",
       "130                     25                 50   \n",
       "129                     25                 10   \n",
       "128                     20                100   \n",
       "125                     15                100   \n",
       "127                     20                 50   \n",
       "126                     20                 10   \n",
       "295                     20                 50   \n",
       "296                     20                100   \n",
       "291                     15                 10   \n",
       "243                     15                 10   \n",
       "341                     15                100   \n",
       "339                     15                 10   \n",
       "345                     25                 10   \n",
       "288                     10                 10   \n",
       "55                      20                 50   \n",
       "48                      10                 10   \n",
       "336                     10                 10   \n",
       "9                       25                 10   \n",
       "\n",
       "                                                params  ...  \\\n",
       "105  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "342  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "51   {'criterion': 'gini', 'max_depth': 2, 'min_imp...  ...   \n",
       "289  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...   \n",
       "54   {'criterion': 'gini', 'max_depth': 2, 'min_imp...  ...   \n",
       "297  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...   \n",
       "147  {'criterion': 'gini', 'max_depth': 10, 'min_im...  ...   \n",
       "340  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "246  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "337  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "298  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...   \n",
       "344  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "249  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "338  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "239  {'criterion': 'entropy', 'max_depth': 1, 'min_...  ...   \n",
       "245  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "251  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "250  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "248  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "247  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "242  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "244  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "237  {'criterion': 'entropy', 'max_depth': 1, 'min_...  ...   \n",
       "253  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "241  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "238  {'criterion': 'entropy', 'max_depth': 1, 'min_...  ...   \n",
       "240  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "252  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "0    {'criterion': 'gini', 'max_depth': 1, 'min_imp...  ...   \n",
       "254  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "..                                                 ...  ...   \n",
       "120  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "123  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "132  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "138  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "137  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "136  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "135  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "124  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "134  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "133  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "383  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "131  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "130  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "129  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "128  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "125  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "127  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "126  {'criterion': 'gini', 'max_depth': 5, 'min_imp...  ...   \n",
       "295  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...   \n",
       "296  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...   \n",
       "291  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...   \n",
       "243  {'criterion': 'entropy', 'max_depth': 2, 'min_...  ...   \n",
       "341  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "339  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "345  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "288  {'criterion': 'entropy', 'max_depth': 5, 'min_...  ...   \n",
       "55   {'criterion': 'gini', 'max_depth': 2, 'min_imp...  ...   \n",
       "48   {'criterion': 'gini', 'max_depth': 2, 'min_imp...  ...   \n",
       "336  {'criterion': 'entropy', 'max_depth': 10, 'min...  ...   \n",
       "9    {'criterion': 'gini', 'max_depth': 1, 'min_imp...  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "105           0.516828           0.527382         0.521763        0.006148   \n",
       "342           0.516971           0.516828         0.519424        0.005120   \n",
       "51            0.516828           0.516828         0.518996        0.004335   \n",
       "289           0.526811           0.516828         0.518825        0.003993   \n",
       "54            0.520679           0.529663         0.520165        0.004978   \n",
       "297           0.526383           0.516828         0.519880        0.003931   \n",
       "147           0.516828           0.516828         0.518597        0.003537   \n",
       "340           0.518825           0.516828         0.517228        0.000799   \n",
       "246           0.521677           0.516828         0.519795        0.003979   \n",
       "337           0.518112           0.516828         0.517085        0.000513   \n",
       "298           0.516828           0.516828         0.517056        0.000456   \n",
       "344           0.516828           0.517256         0.516914        0.000171   \n",
       "249           0.516828           0.516828         0.518026        0.002396   \n",
       "338           0.516828           0.516828         0.516942        0.000228   \n",
       "239           0.516828           0.516828         0.516828        0.000000   \n",
       "245           0.516828           0.516828         0.516828        0.000000   \n",
       "251           0.516828           0.516828         0.516828        0.000000   \n",
       "250           0.516828           0.516828         0.516828        0.000000   \n",
       "248           0.516828           0.516828         0.516828        0.000000   \n",
       "247           0.516828           0.516828         0.516828        0.000000   \n",
       "242           0.516828           0.516828         0.516828        0.000000   \n",
       "244           0.516828           0.516828         0.516828        0.000000   \n",
       "237           0.516828           0.516828         0.516828        0.000000   \n",
       "253           0.516828           0.516828         0.516828        0.000000   \n",
       "241           0.516828           0.516828         0.516828        0.000000   \n",
       "238           0.516828           0.516828         0.516828        0.000000   \n",
       "240           0.516828           0.516828         0.516828        0.000000   \n",
       "252           0.516828           0.516828         0.516828        0.000000   \n",
       "0             0.516828           0.516828         0.516828        0.000000   \n",
       "254           0.516828           0.516828         0.516828        0.000000   \n",
       "..                 ...                ...              ...             ...   \n",
       "120           0.516828           0.516828         0.516828        0.000000   \n",
       "123           0.516828           0.516828         0.516828        0.000000   \n",
       "132           0.516828           0.516828         0.516828        0.000000   \n",
       "138           0.516828           0.516828         0.516828        0.000000   \n",
       "137           0.516828           0.516828         0.516828        0.000000   \n",
       "136           0.516828           0.516828         0.516828        0.000000   \n",
       "135           0.516828           0.516828         0.516828        0.000000   \n",
       "124           0.516828           0.516828         0.516828        0.000000   \n",
       "134           0.516828           0.516828         0.516828        0.000000   \n",
       "133           0.516828           0.516828         0.516828        0.000000   \n",
       "383           0.516828           0.516828         0.516828        0.000000   \n",
       "131           0.516828           0.516828         0.516828        0.000000   \n",
       "130           0.516828           0.516828         0.516828        0.000000   \n",
       "129           0.516828           0.516828         0.516828        0.000000   \n",
       "128           0.516828           0.516828         0.516828        0.000000   \n",
       "125           0.516828           0.516828         0.516828        0.000000   \n",
       "127           0.516828           0.516828         0.516828        0.000000   \n",
       "126           0.516828           0.516828         0.516828        0.000000   \n",
       "295           0.516828           0.516828         0.516828        0.000000   \n",
       "296           0.516828           0.516828         0.516800        0.000057   \n",
       "291           0.522818           0.516828         0.518055        0.002382   \n",
       "243           0.516828           0.520536         0.517598        0.001470   \n",
       "341           0.516828           0.516828         0.517627        0.001597   \n",
       "339           0.516828           0.516828         0.517228        0.000799   \n",
       "345           0.516828           0.516828         0.517798        0.001940   \n",
       "288           0.516828           0.516828         0.517627        0.001597   \n",
       "55            0.516828           0.516828         0.517598        0.001540   \n",
       "48            0.521249           0.516828         0.517712        0.001768   \n",
       "336           0.517684           0.516828         0.517570        0.001106   \n",
       "9             0.515973           0.516828         0.516657        0.000342   \n",
       "\n",
       "     rank_test_score  split4_train_score  mean_train_score  std_train_score  \\\n",
       "105                1            0.527025          0.520971         0.005075   \n",
       "342                5            0.516828          0.519032         0.004371   \n",
       "51                 6            0.516828          0.519074         0.004492   \n",
       "289                7            0.516828          0.519146         0.004635   \n",
       "54                 2            0.529770          0.521855         0.006161   \n",
       "297                3            0.516828          0.521335         0.005566   \n",
       "147                8            0.516828          0.518832         0.004007   \n",
       "340               18            0.516828          0.517292         0.000761   \n",
       "246                4            0.516828          0.522433         0.006884   \n",
       "337               20            0.516828          0.517028         0.000399   \n",
       "298               21            0.516828          0.517178         0.000598   \n",
       "344               23            0.517220          0.516907         0.000157   \n",
       "249               10            0.516828          0.519167         0.004678   \n",
       "338               22            0.516828          0.517035         0.000414   \n",
       "239               24            0.516828          0.516828         0.000000   \n",
       "245               24            0.516828          0.516828         0.000000   \n",
       "251               24            0.516828          0.516828         0.000000   \n",
       "250               24            0.516828          0.516828         0.000000   \n",
       "248               24            0.516828          0.516828         0.000000   \n",
       "247               24            0.516828          0.516828         0.000000   \n",
       "242               24            0.516828          0.516828         0.000000   \n",
       "244               24            0.516828          0.516828         0.000000   \n",
       "237               24            0.516828          0.516828         0.000000   \n",
       "253               24            0.516828          0.516828         0.000000   \n",
       "241               24            0.516828          0.516828         0.000000   \n",
       "238               24            0.516828          0.516828         0.000000   \n",
       "240               24            0.516828          0.516828         0.000000   \n",
       "252               24            0.516828          0.516828         0.000000   \n",
       "0                 24            0.516828          0.516828         0.000000   \n",
       "254               24            0.516828          0.516828         0.000000   \n",
       "..               ...                 ...               ...              ...   \n",
       "120               24            0.516828          0.516828         0.000000   \n",
       "123               24            0.516828          0.516828         0.000000   \n",
       "132               24            0.516828          0.516828         0.000000   \n",
       "138               24            0.516828          0.516828         0.000000   \n",
       "137               24            0.516828          0.516828         0.000000   \n",
       "136               24            0.516828          0.516828         0.000000   \n",
       "135               24            0.516828          0.516828         0.000000   \n",
       "124               24            0.516828          0.516828         0.000000   \n",
       "134               24            0.516828          0.516828         0.000000   \n",
       "133               24            0.516828          0.516828         0.000000   \n",
       "383               24            0.516828          0.516828         0.000000   \n",
       "131               24            0.516828          0.516828         0.000000   \n",
       "130               24            0.516828          0.516828         0.000000   \n",
       "129               24            0.516828          0.516828         0.000000   \n",
       "128               24            0.516828          0.516828         0.000000   \n",
       "125               24            0.516828          0.516828         0.000000   \n",
       "127               24            0.516828          0.516828         0.000000   \n",
       "126               24            0.516828          0.516828         0.000000   \n",
       "295               24            0.516828          0.516857         0.000057   \n",
       "296              383            0.516828          0.516935         0.000214   \n",
       "291                9            0.516828          0.519559         0.005444   \n",
       "243               15            0.526383          0.518739         0.003822   \n",
       "341               13            0.516828          0.518903         0.004150   \n",
       "339               18            0.516828          0.518183         0.002710   \n",
       "345               11            0.516828          0.519509         0.005362   \n",
       "288               13            0.516828          0.519616         0.005558   \n",
       "55                15            0.516828          0.519595         0.005533   \n",
       "48                12            0.516828          0.519830         0.006004   \n",
       "336               17            0.516828          0.520608         0.004671   \n",
       "9                384            0.516828          0.519010         0.004364   \n",
       "\n",
       "     difference  weighted_test_score  \n",
       "105   -0.000792             0.522554  \n",
       "342   -0.000392             0.519816  \n",
       "51     0.000078             0.518918  \n",
       "289    0.000321             0.518504  \n",
       "54     0.001690             0.518475  \n",
       "297    0.001455             0.518426  \n",
       "147    0.000235             0.518361  \n",
       "340    0.000064             0.517163  \n",
       "246    0.002638             0.517156  \n",
       "337   -0.000057             0.517142  \n",
       "298    0.000121             0.516935  \n",
       "344   -0.000007             0.516921  \n",
       "249    0.001141             0.516885  \n",
       "338    0.000093             0.516850  \n",
       "239    0.000000             0.516828  \n",
       "245    0.000000             0.516828  \n",
       "251    0.000000             0.516828  \n",
       "250    0.000000             0.516828  \n",
       "248    0.000000             0.516828  \n",
       "247    0.000000             0.516828  \n",
       "242    0.000000             0.516828  \n",
       "244    0.000000             0.516828  \n",
       "237    0.000000             0.516828  \n",
       "253    0.000000             0.516828  \n",
       "241    0.000000             0.516828  \n",
       "238    0.000000             0.516828  \n",
       "240    0.000000             0.516828  \n",
       "252    0.000000             0.516828  \n",
       "0      0.000000             0.516828  \n",
       "254    0.000000             0.516828  \n",
       "..          ...                  ...  \n",
       "120    0.000000             0.516828  \n",
       "123    0.000000             0.516828  \n",
       "132    0.000000             0.516828  \n",
       "138    0.000000             0.516828  \n",
       "137    0.000000             0.516828  \n",
       "136    0.000000             0.516828  \n",
       "135    0.000000             0.516828  \n",
       "124    0.000000             0.516828  \n",
       "134    0.000000             0.516828  \n",
       "133    0.000000             0.516828  \n",
       "383    0.000000             0.516828  \n",
       "131    0.000000             0.516828  \n",
       "130    0.000000             0.516828  \n",
       "129    0.000000             0.516828  \n",
       "128    0.000000             0.516828  \n",
       "125    0.000000             0.516828  \n",
       "127    0.000000             0.516828  \n",
       "126    0.000000             0.516828  \n",
       "295    0.000029             0.516800  \n",
       "296    0.000135             0.516664  \n",
       "291    0.001505             0.516550  \n",
       "243    0.001141             0.516458  \n",
       "341    0.001276             0.516351  \n",
       "339    0.000956             0.516272  \n",
       "345    0.001711             0.516087  \n",
       "288    0.001989             0.515637  \n",
       "55     0.001997             0.515602  \n",
       "48     0.002118             0.515595  \n",
       "336    0.003038             0.514532  \n",
       "9      0.002353             0.514304  \n",
       "\n",
       "[384 rows x 23 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_df.drop(['split0_train_score', 'split1_train_score', 'split2_train_score', 'split3_train_score'], axis=1).sort_values(by='weighted_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3 = RandomForestClassifier(criterion='entropy', max_depth=10, min_impurity_decrease=.001, min_samples_leaf=20, n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.001, min_impurity_split=None,\n",
       "            min_samples_leaf=20, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds3 = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix test: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm(y_test,preds3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      4545\n",
      "           1       0.62      0.62      0.62      4220\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      8765\n",
      "   macro avg       0.63      0.63      0.63      8765\n",
      "weighted avg       0.63      0.63      0.63      8765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are back to similar results to a baseline random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying the same things with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds4 = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix test: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm(y_test, preds4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.84      0.64      4545\n",
      "           1       0.50      0.18      0.26      4220\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      8765\n",
      "   macro avg       0.51      0.51      0.45      8765\n",
      "weighted avg       0.51      0.52      0.46      8765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 34.8min\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 53.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=3500, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'C': [1, 5, 10], 'gamma': [0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(cache_size=3500)\n",
    "param_grid = {\n",
    "    \"C\": [1,5,10],\n",
    "    \"gamma\": [.1,1,10],\n",
    "}\n",
    "gs_svm = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy',  n_jobs=-1, verbose=2)\n",
    "gs_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.1}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model2 = svm.SVC(cache_size=3500, C=1, gamma=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=3500, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds5 = svm_model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix test: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm(y_test, preds5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.84      0.64      4545\n",
      "           1       0.50      0.18      0.26      4220\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      8765\n",
      "   macro avg       0.51      0.51      0.45      8765\n",
      "weighted avg       0.51      0.52      0.46      8765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([311.85959396, 330.15955606, 362.37009883, 464.89218373,\n",
       "        435.80827136, 529.24332252, 463.52399964, 441.17959652,\n",
       "        384.91541595]),\n",
       " 'std_fit_time': array([ 0.96863131,  7.25338889, 10.67409284,  3.21678955, 21.06340497,\n",
       "         4.34331819,  2.1706586 , 22.61505703,  9.73633943]),\n",
       " 'mean_score_time': array([27.1959991 , 27.13160496, 27.00774589, 26.96688061, 26.89206944,\n",
       "        27.27660022, 27.34908252, 27.03344569, 17.5207253 ]),\n",
       " 'std_score_time': array([0.29245691, 0.18973374, 0.2437964 , 0.22237818, 0.21813818,\n",
       "        0.3051754 , 0.65599666, 0.25417796, 0.54907852]),\n",
       " 'param_C': masked_array(data=[1, 1, 1, 5, 5, 5, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.1, 1, 10, 0.1, 1, 10, 0.1, 1, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'gamma': 0.1},\n",
       "  {'C': 1, 'gamma': 1},\n",
       "  {'C': 1, 'gamma': 10},\n",
       "  {'C': 5, 'gamma': 0.1},\n",
       "  {'C': 5, 'gamma': 1},\n",
       "  {'C': 5, 'gamma': 10},\n",
       "  {'C': 10, 'gamma': 0.1},\n",
       "  {'C': 10, 'gamma': 1},\n",
       "  {'C': 10, 'gamma': 10}],\n",
       " 'split0_test_score': array([0.51968055, 0.51611523, 0.51554478, 0.51953793, 0.51825442,\n",
       "        0.51583001, 0.51939532, 0.51825442, 0.51583001]),\n",
       " 'split1_test_score': array([0.52067884, 0.51369082, 0.51668568, 0.52281803, 0.51511694,\n",
       "        0.51711352, 0.52310325, 0.51511694, 0.51711352]),\n",
       " 'split2_test_score': array([0.51754136, 0.52039361, 0.51739875, 0.51497433, 0.51953793,\n",
       "        0.51754136, 0.51483172, 0.51953793, 0.51754136]),\n",
       " 'split3_test_score': array([0.52495722, 0.51939532, 0.51568739, 0.52196235, 0.51853965,\n",
       "        0.51554478, 0.52239019, 0.51853965, 0.51554478]),\n",
       " 'split4_test_score': array([0.52324586, 0.51853965, 0.51625784, 0.5259555 , 0.52067884,\n",
       "        0.51625784, 0.52581289, 0.52067884, 0.51611523]),\n",
       " 'mean_test_score': array([0.52122076, 0.51762693, 0.51631489, 0.52104963, 0.51842556,\n",
       "        0.5164575 , 0.52110667, 0.51842556, 0.51642898]),\n",
       " 'std_test_score': array([0.00261787, 0.00242458, 0.00067857, 0.00366667, 0.00186032,\n",
       "        0.00075786, 0.00374396, 0.00186032, 0.00076746]),\n",
       " 'rank_test_score': array([1, 6, 9, 3, 4, 7, 2, 4, 8]),\n",
       " 'split0_train_score': array([0.99187108, 0.9988591 , 0.99910867, 0.9971834 , 0.99910867,\n",
       "        0.99910867, 0.99796777, 0.99910867, 0.99910867]),\n",
       " 'split1_train_score': array([0.99133628, 0.99857387, 0.99878779, 0.99682687, 0.99878779,\n",
       "        0.99882345, 0.99764689, 0.99878779, 0.9988591 ]),\n",
       " 'split2_train_score': array([0.99226326, 0.99878779, 0.99900171, 0.99696948, 0.99900171,\n",
       "        0.99907302, 0.99800342, 0.99900171, 0.99900171]),\n",
       " 'split3_train_score': array([0.99080148, 0.99853822, 0.99903736, 0.99675556, 0.9988591 ,\n",
       "        0.99903736, 0.9977895 , 0.9988591 , 0.99900171]),\n",
       " 'split4_train_score': array([0.99162151, 0.99864518, 0.99903736, 0.99679122, 0.99900171,\n",
       "        0.99907302, 0.99782516, 0.99900171, 0.99903736]),\n",
       " 'mean_train_score': array([0.99157872, 0.99868083, 0.99899458, 0.99690531, 0.9989518 ,\n",
       "        0.9990231 , 0.99784655, 0.9989518 , 0.99900171]),\n",
       " 'std_train_score': array([4.93715898e-04, 1.23506190e-04, 1.09077713e-04, 1.56873930e-04,\n",
       "        1.14090131e-04, 1.02343840e-04, 1.28746934e-04, 1.14090131e-04,\n",
       "        8.13017274e-05])}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "svm_df = pd.DataFrame(gs_svm.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>311.859594</td>\n",
       "      <td>0.968631</td>\n",
       "      <td>27.195999</td>\n",
       "      <td>0.292457</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.519681</td>\n",
       "      <td>0.520679</td>\n",
       "      <td>0.517541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521221</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991871</td>\n",
       "      <td>0.991336</td>\n",
       "      <td>0.992263</td>\n",
       "      <td>0.990801</td>\n",
       "      <td>0.991622</td>\n",
       "      <td>0.991579</td>\n",
       "      <td>0.000494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>330.159556</td>\n",
       "      <td>7.253389</td>\n",
       "      <td>27.131605</td>\n",
       "      <td>0.189734</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1, 'gamma': 1}</td>\n",
       "      <td>0.516115</td>\n",
       "      <td>0.513691</td>\n",
       "      <td>0.520394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517627</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>6</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.998574</td>\n",
       "      <td>0.998788</td>\n",
       "      <td>0.998538</td>\n",
       "      <td>0.998645</td>\n",
       "      <td>0.998681</td>\n",
       "      <td>0.000124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>362.370099</td>\n",
       "      <td>10.674093</td>\n",
       "      <td>27.007746</td>\n",
       "      <td>0.243796</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 1, 'gamma': 10}</td>\n",
       "      <td>0.515545</td>\n",
       "      <td>0.516686</td>\n",
       "      <td>0.517399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516315</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.998788</td>\n",
       "      <td>0.999002</td>\n",
       "      <td>0.999037</td>\n",
       "      <td>0.999037</td>\n",
       "      <td>0.998995</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>464.892184</td>\n",
       "      <td>3.216790</td>\n",
       "      <td>26.966881</td>\n",
       "      <td>0.222378</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 5, 'gamma': 0.1}</td>\n",
       "      <td>0.519538</td>\n",
       "      <td>0.522818</td>\n",
       "      <td>0.514974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521050</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.997183</td>\n",
       "      <td>0.996827</td>\n",
       "      <td>0.996969</td>\n",
       "      <td>0.996756</td>\n",
       "      <td>0.996791</td>\n",
       "      <td>0.996905</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>435.808271</td>\n",
       "      <td>21.063405</td>\n",
       "      <td>26.892069</td>\n",
       "      <td>0.218138</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 5, 'gamma': 1}</td>\n",
       "      <td>0.518254</td>\n",
       "      <td>0.515117</td>\n",
       "      <td>0.519538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518426</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.998788</td>\n",
       "      <td>0.999002</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.999002</td>\n",
       "      <td>0.998952</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0     311.859594      0.968631        27.195999        0.292457       1   \n",
       "1     330.159556      7.253389        27.131605        0.189734       1   \n",
       "2     362.370099     10.674093        27.007746        0.243796       1   \n",
       "3     464.892184      3.216790        26.966881        0.222378       5   \n",
       "4     435.808271     21.063405        26.892069        0.218138       5   \n",
       "\n",
       "  param_gamma                  params  split0_test_score  split1_test_score  \\\n",
       "0         0.1  {'C': 1, 'gamma': 0.1}           0.519681           0.520679   \n",
       "1           1    {'C': 1, 'gamma': 1}           0.516115           0.513691   \n",
       "2          10   {'C': 1, 'gamma': 10}           0.515545           0.516686   \n",
       "3         0.1  {'C': 5, 'gamma': 0.1}           0.519538           0.522818   \n",
       "4           1    {'C': 5, 'gamma': 1}           0.518254           0.515117   \n",
       "\n",
       "   split2_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.517541  ...         0.521221        0.002618                1   \n",
       "1           0.520394  ...         0.517627        0.002425                6   \n",
       "2           0.517399  ...         0.516315        0.000679                9   \n",
       "3           0.514974  ...         0.521050        0.003667                3   \n",
       "4           0.519538  ...         0.518426        0.001860                4   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.991871            0.991336            0.992263   \n",
       "1            0.998859            0.998574            0.998788   \n",
       "2            0.999109            0.998788            0.999002   \n",
       "3            0.997183            0.996827            0.996969   \n",
       "4            0.999109            0.998788            0.999002   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.990801            0.991622          0.991579         0.000494  \n",
       "1            0.998538            0.998645          0.998681         0.000124  \n",
       "2            0.999037            0.999037          0.998995         0.000109  \n",
       "3            0.996756            0.996791          0.996905         0.000157  \n",
       "4            0.998859            0.999002          0.998952         0.000114  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>311.859594</td>\n",
       "      <td>0.968631</td>\n",
       "      <td>27.195999</td>\n",
       "      <td>0.292457</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.519681</td>\n",
       "      <td>0.520679</td>\n",
       "      <td>0.517541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521221</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991871</td>\n",
       "      <td>0.991336</td>\n",
       "      <td>0.992263</td>\n",
       "      <td>0.990801</td>\n",
       "      <td>0.991622</td>\n",
       "      <td>0.991579</td>\n",
       "      <td>0.000494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>463.524000</td>\n",
       "      <td>2.170659</td>\n",
       "      <td>27.349083</td>\n",
       "      <td>0.655997</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1}</td>\n",
       "      <td>0.519395</td>\n",
       "      <td>0.523103</td>\n",
       "      <td>0.514832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521107</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997968</td>\n",
       "      <td>0.997647</td>\n",
       "      <td>0.998003</td>\n",
       "      <td>0.997790</td>\n",
       "      <td>0.997825</td>\n",
       "      <td>0.997847</td>\n",
       "      <td>0.000129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>464.892184</td>\n",
       "      <td>3.216790</td>\n",
       "      <td>26.966881</td>\n",
       "      <td>0.222378</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 5, 'gamma': 0.1}</td>\n",
       "      <td>0.519538</td>\n",
       "      <td>0.522818</td>\n",
       "      <td>0.514974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521050</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.997183</td>\n",
       "      <td>0.996827</td>\n",
       "      <td>0.996969</td>\n",
       "      <td>0.996756</td>\n",
       "      <td>0.996791</td>\n",
       "      <td>0.996905</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>435.808271</td>\n",
       "      <td>21.063405</td>\n",
       "      <td>26.892069</td>\n",
       "      <td>0.218138</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 5, 'gamma': 1}</td>\n",
       "      <td>0.518254</td>\n",
       "      <td>0.515117</td>\n",
       "      <td>0.519538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518426</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.998788</td>\n",
       "      <td>0.999002</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.999002</td>\n",
       "      <td>0.998952</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>441.179597</td>\n",
       "      <td>22.615057</td>\n",
       "      <td>27.033446</td>\n",
       "      <td>0.254178</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 10, 'gamma': 1}</td>\n",
       "      <td>0.518254</td>\n",
       "      <td>0.515117</td>\n",
       "      <td>0.519538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518426</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.998788</td>\n",
       "      <td>0.999002</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.999002</td>\n",
       "      <td>0.998952</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>330.159556</td>\n",
       "      <td>7.253389</td>\n",
       "      <td>27.131605</td>\n",
       "      <td>0.189734</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1, 'gamma': 1}</td>\n",
       "      <td>0.516115</td>\n",
       "      <td>0.513691</td>\n",
       "      <td>0.520394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517627</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>6</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.998574</td>\n",
       "      <td>0.998788</td>\n",
       "      <td>0.998538</td>\n",
       "      <td>0.998645</td>\n",
       "      <td>0.998681</td>\n",
       "      <td>0.000124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>529.243323</td>\n",
       "      <td>4.343318</td>\n",
       "      <td>27.276600</td>\n",
       "      <td>0.305175</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 5, 'gamma': 10}</td>\n",
       "      <td>0.515830</td>\n",
       "      <td>0.517114</td>\n",
       "      <td>0.517541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516458</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.998823</td>\n",
       "      <td>0.999073</td>\n",
       "      <td>0.999037</td>\n",
       "      <td>0.999073</td>\n",
       "      <td>0.999023</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>384.915416</td>\n",
       "      <td>9.736339</td>\n",
       "      <td>17.520725</td>\n",
       "      <td>0.549079</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10, 'gamma': 10}</td>\n",
       "      <td>0.515830</td>\n",
       "      <td>0.517114</td>\n",
       "      <td>0.517541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516429</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.999002</td>\n",
       "      <td>0.999002</td>\n",
       "      <td>0.999037</td>\n",
       "      <td>0.999002</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>362.370099</td>\n",
       "      <td>10.674093</td>\n",
       "      <td>27.007746</td>\n",
       "      <td>0.243796</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 1, 'gamma': 10}</td>\n",
       "      <td>0.515545</td>\n",
       "      <td>0.516686</td>\n",
       "      <td>0.517399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516315</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.998788</td>\n",
       "      <td>0.999002</td>\n",
       "      <td>0.999037</td>\n",
       "      <td>0.999037</td>\n",
       "      <td>0.998995</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0     311.859594      0.968631        27.195999        0.292457       1   \n",
       "6     463.524000      2.170659        27.349083        0.655997      10   \n",
       "3     464.892184      3.216790        26.966881        0.222378       5   \n",
       "4     435.808271     21.063405        26.892069        0.218138       5   \n",
       "7     441.179597     22.615057        27.033446        0.254178      10   \n",
       "1     330.159556      7.253389        27.131605        0.189734       1   \n",
       "5     529.243323      4.343318        27.276600        0.305175       5   \n",
       "8     384.915416      9.736339        17.520725        0.549079      10   \n",
       "2     362.370099     10.674093        27.007746        0.243796       1   \n",
       "\n",
       "  param_gamma                   params  split0_test_score  split1_test_score  \\\n",
       "0         0.1   {'C': 1, 'gamma': 0.1}           0.519681           0.520679   \n",
       "6         0.1  {'C': 10, 'gamma': 0.1}           0.519395           0.523103   \n",
       "3         0.1   {'C': 5, 'gamma': 0.1}           0.519538           0.522818   \n",
       "4           1     {'C': 5, 'gamma': 1}           0.518254           0.515117   \n",
       "7           1    {'C': 10, 'gamma': 1}           0.518254           0.515117   \n",
       "1           1     {'C': 1, 'gamma': 1}           0.516115           0.513691   \n",
       "5          10    {'C': 5, 'gamma': 10}           0.515830           0.517114   \n",
       "8          10   {'C': 10, 'gamma': 10}           0.515830           0.517114   \n",
       "2          10    {'C': 1, 'gamma': 10}           0.515545           0.516686   \n",
       "\n",
       "   split2_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.517541  ...         0.521221        0.002618                1   \n",
       "6           0.514832  ...         0.521107        0.003744                2   \n",
       "3           0.514974  ...         0.521050        0.003667                3   \n",
       "4           0.519538  ...         0.518426        0.001860                4   \n",
       "7           0.519538  ...         0.518426        0.001860                4   \n",
       "1           0.520394  ...         0.517627        0.002425                6   \n",
       "5           0.517541  ...         0.516458        0.000758                7   \n",
       "8           0.517541  ...         0.516429        0.000767                8   \n",
       "2           0.517399  ...         0.516315        0.000679                9   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.991871            0.991336            0.992263   \n",
       "6            0.997968            0.997647            0.998003   \n",
       "3            0.997183            0.996827            0.996969   \n",
       "4            0.999109            0.998788            0.999002   \n",
       "7            0.999109            0.998788            0.999002   \n",
       "1            0.998859            0.998574            0.998788   \n",
       "5            0.999109            0.998823            0.999073   \n",
       "8            0.999109            0.998859            0.999002   \n",
       "2            0.999109            0.998788            0.999002   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.990801            0.991622          0.991579         0.000494  \n",
       "6            0.997790            0.997825          0.997847         0.000129  \n",
       "3            0.996756            0.996791          0.996905         0.000157  \n",
       "4            0.998859            0.999002          0.998952         0.000114  \n",
       "7            0.998859            0.999002          0.998952         0.000114  \n",
       "1            0.998538            0.998645          0.998681         0.000124  \n",
       "5            0.999037            0.999073          0.999023         0.000102  \n",
       "8            0.999002            0.999037          0.999002         0.000081  \n",
       "2            0.999037            0.999037          0.998995         0.000109  \n",
       "\n",
       "[9 rows x 22 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_df.sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our results are majorly overfitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 29.0min\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 43.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=3500, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'C': [0.1, 0.5, 0.8], 'gamma': [0.1, 0.5, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(cache_size=3500)\n",
    "param_grid = {\n",
    "    \"C\": [.1,.5,.8],\n",
    "    \"gamma\": [.1,.5,1],\n",
    "}\n",
    "gs_svm2 = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy',  n_jobs=-1, verbose=2)\n",
    "gs_svm2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.8, 'gamma': 0.1}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lraic\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "svm2_df = pd.DataFrame(gs_svm2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>314.488108</td>\n",
       "      <td>0.892504</td>\n",
       "      <td>27.274000</td>\n",
       "      <td>0.152453</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.8, 'gamma': 0.1}</td>\n",
       "      <td>0.519253</td>\n",
       "      <td>0.522390</td>\n",
       "      <td>0.521107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520993</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984633</td>\n",
       "      <td>0.984847</td>\n",
       "      <td>0.985454</td>\n",
       "      <td>0.984348</td>\n",
       "      <td>0.984063</td>\n",
       "      <td>0.984669</td>\n",
       "      <td>0.000473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>363.834914</td>\n",
       "      <td>1.595796</td>\n",
       "      <td>27.181001</td>\n",
       "      <td>0.177785</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'C': 0.8, 'gamma': 0.5}</td>\n",
       "      <td>0.515687</td>\n",
       "      <td>0.515260</td>\n",
       "      <td>0.519538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517399</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>2</td>\n",
       "      <td>0.996399</td>\n",
       "      <td>0.996256</td>\n",
       "      <td>0.996542</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.996613</td>\n",
       "      <td>0.996378</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>305.110431</td>\n",
       "      <td>3.940206</td>\n",
       "      <td>27.270999</td>\n",
       "      <td>0.161193</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.5, 'gamma': 0.1}</td>\n",
       "      <td>0.516971</td>\n",
       "      <td>0.517114</td>\n",
       "      <td>0.517399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517313</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>3</td>\n",
       "      <td>0.614233</td>\n",
       "      <td>0.611274</td>\n",
       "      <td>0.611167</td>\n",
       "      <td>0.609776</td>\n",
       "      <td>0.609277</td>\n",
       "      <td>0.611145</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>252.131000</td>\n",
       "      <td>21.096494</td>\n",
       "      <td>16.257812</td>\n",
       "      <td>2.627787</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.8, 'gamma': 1}</td>\n",
       "      <td>0.515117</td>\n",
       "      <td>0.515830</td>\n",
       "      <td>0.518967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517114</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>4</td>\n",
       "      <td>0.997861</td>\n",
       "      <td>0.997326</td>\n",
       "      <td>0.997504</td>\n",
       "      <td>0.997397</td>\n",
       "      <td>0.997683</td>\n",
       "      <td>0.997554</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>263.655060</td>\n",
       "      <td>3.356710</td>\n",
       "      <td>26.607013</td>\n",
       "      <td>0.241058</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.1}</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>326.676852</td>\n",
       "      <td>8.500405</td>\n",
       "      <td>27.401342</td>\n",
       "      <td>0.152860</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.5}</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>338.385158</td>\n",
       "      <td>12.917754</td>\n",
       "      <td>27.571000</td>\n",
       "      <td>0.516469</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 1}</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>324.652999</td>\n",
       "      <td>20.736021</td>\n",
       "      <td>27.148400</td>\n",
       "      <td>0.079678</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.5, 'gamma': 1}</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516800</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>8</td>\n",
       "      <td>0.530234</td>\n",
       "      <td>0.530234</td>\n",
       "      <td>0.527382</td>\n",
       "      <td>0.528808</td>\n",
       "      <td>0.527596</td>\n",
       "      <td>0.528851</td>\n",
       "      <td>0.001230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>355.069998</td>\n",
       "      <td>1.481633</td>\n",
       "      <td>27.250800</td>\n",
       "      <td>0.369830</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'C': 0.5, 'gamma': 0.5}</td>\n",
       "      <td>0.516400</td>\n",
       "      <td>0.516543</td>\n",
       "      <td>0.516971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516714</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>9</td>\n",
       "      <td>0.542356</td>\n",
       "      <td>0.542784</td>\n",
       "      <td>0.539825</td>\n",
       "      <td>0.541179</td>\n",
       "      <td>0.539397</td>\n",
       "      <td>0.541108</td>\n",
       "      <td>0.001338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "6     314.488108      0.892504        27.274000        0.152453     0.8   \n",
       "7     363.834914      1.595796        27.181001        0.177785     0.8   \n",
       "3     305.110431      3.940206        27.270999        0.161193     0.5   \n",
       "8     252.131000     21.096494        16.257812        2.627787     0.8   \n",
       "0     263.655060      3.356710        26.607013        0.241058     0.1   \n",
       "1     326.676852      8.500405        27.401342        0.152860     0.1   \n",
       "2     338.385158     12.917754        27.571000        0.516469     0.1   \n",
       "5     324.652999     20.736021        27.148400        0.079678     0.5   \n",
       "4     355.069998      1.481633        27.250800        0.369830     0.5   \n",
       "\n",
       "  param_gamma                    params  split0_test_score  split1_test_score  \\\n",
       "6         0.1  {'C': 0.8, 'gamma': 0.1}           0.519253           0.522390   \n",
       "7         0.5  {'C': 0.8, 'gamma': 0.5}           0.515687           0.515260   \n",
       "3         0.1  {'C': 0.5, 'gamma': 0.1}           0.516971           0.517114   \n",
       "8           1    {'C': 0.8, 'gamma': 1}           0.515117           0.515830   \n",
       "0         0.1  {'C': 0.1, 'gamma': 0.1}           0.516828           0.516828   \n",
       "1         0.5  {'C': 0.1, 'gamma': 0.5}           0.516828           0.516828   \n",
       "2           1    {'C': 0.1, 'gamma': 1}           0.516828           0.516828   \n",
       "5           1    {'C': 0.5, 'gamma': 1}           0.516828           0.516828   \n",
       "4         0.5  {'C': 0.5, 'gamma': 0.5}           0.516400           0.516543   \n",
       "\n",
       "   split2_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "6           0.521107  ...         0.520993        0.001348                1   \n",
       "7           0.519538  ...         0.517399        0.001646                2   \n",
       "3           0.517399  ...         0.517313        0.000294                3   \n",
       "8           0.518967  ...         0.517114        0.001490                4   \n",
       "0           0.516828  ...         0.516828        0.000000                5   \n",
       "1           0.516828  ...         0.516828        0.000000                5   \n",
       "2           0.516828  ...         0.516828        0.000000                5   \n",
       "5           0.516828  ...         0.516800        0.000057                8   \n",
       "4           0.516971  ...         0.516714        0.000210                9   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "6            0.984633            0.984847            0.985454   \n",
       "7            0.996399            0.996256            0.996542   \n",
       "3            0.614233            0.611274            0.611167   \n",
       "8            0.997861            0.997326            0.997504   \n",
       "0            0.516828            0.516828            0.516828   \n",
       "1            0.516828            0.516828            0.516828   \n",
       "2            0.516828            0.516828            0.516828   \n",
       "5            0.530234            0.530234            0.527382   \n",
       "4            0.542356            0.542784            0.539825   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "6            0.984348            0.984063          0.984669         0.000473  \n",
       "7            0.996078            0.996613          0.996378         0.000193  \n",
       "3            0.609776            0.609277          0.611145         0.001727  \n",
       "8            0.997397            0.997683          0.997554         0.000195  \n",
       "0            0.516828            0.516828          0.516828         0.000000  \n",
       "1            0.516828            0.516828          0.516828         0.000000  \n",
       "2            0.516828            0.516828          0.516828         0.000000  \n",
       "5            0.528808            0.527596          0.528851         0.001230  \n",
       "4            0.541179            0.539397          0.541108         0.001338  \n",
       "\n",
       "[9 rows x 22 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm2_df.sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model3 = svm.SVC(cache_size=3500, C=.5, gamma=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.5, cache_size=3500, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.5, cache_size=3500, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds6 = svm_model3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix test: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEKCAYAAADticXcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8FVX6x/HPc3MJhN4kIER6EVCxF0QFkaaCSBGwoKLYsK0/RWRXlBXLqrgWUGBFQV3KKigiRVEQRaSqdASlRWkCImCAlPP74w4xgZQbSXJvxu+b17xed86cmTmj8OTkmXPONeccIiLiD4FIN0BERPKPgrqIiI8oqIuI+IiCuoiIjyioi4j4iIK6iIiPKKiLiPiIgrqIiI8oqIuI+Egw0g3ITtzp/TTVVY6xZ9ErkW6CRKESQex4r5GXmJP0zSvHfb+Cop66iIiPRG1PXUSkUJk/+rgK6iIiAIGYSLcgXyioi4gAWNSmyfNEQV1EBJR+ERHxFfXURUR8RD11EREfUU9dRMRHNPpFRMRHlH4REfERpV9ERHxEPXURER9RUBcR8ZEYvSgVEfEP5dRFRHxE6RcRER9RT11ExEfUUxcR8RH11EVEfMQnywT44/cNEZHjZYHwt3AuZxZjZt+Y2VRvv7aZLTCzdWY2wcxivfLi3v5673itDNcY4JWvNbO24dxXQV1EBELpl3C38NwLrM6w/wzwgnOuPrAH6OOV9wH2OOfqAS949TCzxkAPoAnQDhhuZrn+OqGgLiIC+dpTN7MawOXAf7x9A1oB73pVxgBXeZ87eft4xy/16ncCxjvnDjnnNgDrgXNyu7eCuogI5Hf65d/AQ0Cat18J+NU5l+LtJwLVvc/VgS0A3vG9Xv308izOyZaCuogIhF6UhrmZWV8zW5xh63vkMmZ2BbDDObckw9Wzytm4XI7ldE62NPpFRATyNKTROTcSGJnN4eZARzPrAJQAyhLquZc3s6DXG68B/OzVTwQSgEQzCwLlgN0Zyo/IeE621FMXEYF8S7845wY452o452oRetH5mXPuWmA20NWr1hv4wPs8xdvHO/6Zc8555T280TG1gfrAwtweQz11EREojMlH/YHxZvYE8A3wulf+OvCWma0n1EPvAeCcW2lmE4FVQApwl3MuNbebKKiLiABWAEHdOTcHmON9/pEsRq845w4C3bI5fwgwJC/3VFAXEaFggnokKKiLiAAWUFAXEfEN9dRFRHxEQV1ExEcU1EVE/MQfMV1BXUQE1FMXEfGVQMAfE+wV1EVEUE9dRMRf/BHTFdRFREA9dRERX1FQFxHxES0TICLiI+qpi4j4iF+Cuj8GZhZRgYAxf1x/3nvx9kzlQ/t3Y+e859P3T6pWgWmv3c3CCQOYOepeqlcpn37siXs6sfh/j7D4f4/Qtc0ZhdZ2KXypqal073IV/e68DQDnHC+/+AJXdmjLVVe25523x0a4hUWbmYW9RTP11COoX6+WrN2wnTKlSqSXndH4JMqVjstU76n7O/PORwt558MFXHx2Awbf3ZE+/xhLuwub0OzkBM7t8TTFiwX5+PX7mDlvFfsOHCzsR5FC8M5bY6lTpy77D+wH4IP3J7Ft21Y+mDqdQCDArl27ItzCoi3ag3W41FOPkOpVytPuwia8Mfmr9LJAwHjyvqsY+OL7meo2qlONOQvWAvD5ou+54pJTADi5TlW+WLKO1NQ0fj94mOXfJ9LmgpML7yGk0Gzfto0v5s6hc5eu6WUTx4/jttvvSp8JWalSpUg1zx8sD1sUU1CPkGcf7MLAF98nLc2ll91xzcV89Plytv3yW6a6y7//iasubQZAp1anUbZ0HBXLlWLZ9z/Rtnlj4koUo1L5Ulx8VgNqVK1QqM8hheNfTz/J/Q88mGkqe+KWLcycMY2e3a/mzttuYdOmjZFroA8EAoGwt2gW3a3zqfYtmrJj9z6+Wb0lvazaCeW4+rLTGT7+82PqD3hhMi3OrMf8cf1pcWY9ftq+h5TUVD79eg0zvlzF7DcfYMxTN7Fg2QZSUtIK81GkEHw+ZzYVK1akcZOmmcoPHz5MbPHijJs4iau7dmfQ3x+JUAv9wS85dXPO5V4rAuJO7xedDcsHg+/uSK/LzyYlNY3iscUoW6oEh5JTOHQ4hUOHkwFIqFqBDYm7aNrp8UznloqL5bvJ/6Beu38cc903n7yRcdMWMvPLVYXyHJGwZ9ErkW5CoXvxheeZ+uEHBGOCHDp0iAMH9tOq9WWsWrmC4SP+Q/XqNXDOceF5ZzFvwZJINzciSgSPPymS0O+DsGPOllc6RW1k14vSCHj05Sk8+vIUAFqcWZ/7briULve+lqnOznnPpwf0SuVLsXvv7zjnePDmtoz54GsglIMvX6Yku/ceoGn9E2la/0RmzV9TuA8jBe7e+x/g3vsfAGDRwgWMeXM0Tz3zHP8e+hwLF3xN56u7snjRQmrWrBXZhhZx0d4DD1eBBXUzawR0AqoDDvgZmOKcW11Q9/Sri86qz+C7O+IcfLl0Pfc9NRGAYsEYZo2+D4B9+w9y88AxpKYq/fJXcfMtfXmk///x9tgxlCxZkkGDh0S6SUWaX4J6gaRfzKw/0BMYDyR6xTWAHsB459zTuV3Dz+kX+fP+iukXyV1+pF9q3Ts17Jiz8cUrovYnQEH11PsATZxzyRkLzWwosBLINaiLiBQmrf2SszTgRGDTUeXVvGNZMrO+QF+AYI1LCFZuUkDNKzxrPnqcfQcOkZqWRkpqGhde+y+ubn06A2/vQKPa8bS4/jmWrtp8zHnFY4PMev0+YmODBGNimDzrG554bRoArw7qxRmNT8Iw1m/ewa2PvsWBpMPc0eNi+nRpzpZte+h+/0iSU1K5oFkdOl3ajP7PTyrsR5cwzftiLs88PYS01DQ6d+lGn1v7Zjr+weRJvPD8v6hSJR6AHr2u4+qu3VizejVD/vkY+/fvJyYmwC1976Bd+w4ADHjoAdat+56LLm7JPff9DYARrw6jQcOGtGzVunAfsIjwS/qloIL6fcCnZrYOODJu7ySgHtAvu5OccyOBkeCv9Eu7vi+y69cD6fsrf/iZHg+M4pW/98z2nEOHU2jX9yUOJB0mGAzw2ei/8fG8VSxcvpGHnpuUPmv0mQeu5o4eF/PcG59wY+fzObv7Uwy68wouu+Bkps1dwcO3tueGh0cX+DPKn5OamsqTQwYzYtQbxMfH0+uarlzSshV169XLVK9Nuw488vdHM5WViCvBE089Q82atdixYzs9u3XhguYXsm3rzwC8O/lDbry+F/v27ePgwSRWLF/ObXfcVWjPVtQoqOfAOTfDzBoA5xB6UWqEcuuLnHOpBXHPomTthu1h1TuQdBgIvRANBmM48v4j4zIAJYoXI+N7kWLBGEqWKEZySiq9rjiHmV+u5Nd9SfnYeslPK5YvIyGhJjUSEgBo1+Fy5sz+9JignpVatWqnf65SJZ6KFSuyZ89ugsFiHDx0iLS0NJKTk4kJBBj+8kvcefc9BfYcfuCTmF5wo1+cc2nA1wV1/aLCOceHw/vhnOP19+YxetK8sM8NBIyv/tufugknMGLCXBat+CObNeKx62h7YWPW/LiNh4eGUiv/Hvspn499gNU/bGX+tz8ycWhfOvYblu/PJPlnx/btVK1WNX2/Snw8y5ctO6bep598zNIli6hZszYP9h9A1WrVMh1fvmwZySnJJCScRCAQoFrVavTo2pnLO3Zi8+bNOBwnn9y4wJ+nKFNPXcLS6qYX2LpzLydUKM3U1/qxduM25i39Iaxz09Ic5/V4mnKl45gw9FYa163Gqh+2AnDbY28TCBhD+3eja5szeWvK14z7aBHjPloEwCN92zN8/BzaNm/CtVecQ+K2PfQfOplonWz2V+U49v/H0cHl4pYtaX/5FcTGxjJxwjj+/kh//vPGHysy7ty5g4EDHuSJJ59Jn8L+0ICB6cfvvvN2/vHY44wa8Srfr13Deec3p0u37gX0REVXwCcvSrVMQAHbunMvADv37GfKZ8s4u0mtPF9j7/4k5i5eR5sLMve00tIc7368NH1dmCOqnVCOM5vUZOqc5Tx8S1uu6z+aQ8kptDyn4Z9+DikY8fFV2bZ1W/r+ju3bqVKlSqY65ctXIDY2FoAuXbuzetXK9GP79++n3x230e+e+zj1tMx/DwBmfzaLJk2bkpSUxPp163h26ItM/fADkpKUkjuaWfhbztexEma20My+M7OVZva4V/6Oma01sxVmNtrMinnlZmYvmdl6M1tmZmdkuFZvM1vnbb3DeQ4F9QJUskQspUsWT//c+vxGrPzh57DOrVyhdPoSvCWKF6PVuQ1ZuzGUi6+TUDm93uUXncL3GzPn6B+983IGD5/qnRuLc6EfACXjih33M0n+atL0FDZv3khi4haSDx9mxrSPuLhlq0x1du7ckf55zuzPqF2nLgDJhw9z/z13cWXHTrRp2/6YaycnJ/POW2PpfVMfDiYdTP8N4EiuXTILBCzsLReHgFbOudOAZkA7MzsPeAdoBJwCxAG3ePXbA/W9rS/wKoCZVQQGAecSej85yMxyXbFP6ZcCVKVSGSYMvRWAYEwME6Yv5pOvVtOx5akM7d+NyhVKM+ml21m29ic63jWMaieUY/ijveh896tUrVyWUYOvJyYQIBAw3vtkKdO/WIGZ8Z/B11OmVBxmoRUc73lyQvo9T2tYA4Dv1obmfI15/ysW/+8RErftYciI6YX/H0FyFAwGGTDwUe7oewtpaalc1bkL9erVZ9jLL9KkSVMuaXUp/337LebM/oxgTAxly5Xjn0OeAmDmzOksXbKYvb/+ypT3JwMweMjTNDo5tPzyhHHv0LFTZ+Li4mjQsCHOObpcdSUXtriIsmXLRuyZo1V+pdRdKMe539st5m3OOTftj3vZQkITMiE0836sd97XZlbezKoBlwCfOOd2e+d8ArQDxuX4HNGaY/XTkEbJP5pRKlnJjxmlTf/+SdgxZ8UTl+V4PzOLAZYQGsY9zDnXP8OxYsAC4F7n3BdmNhV42jn3pXf8U6A/oaBewjn3hFf+DyDJOfdcTvdW+kVEhLzl1M2sr5ktzrBlmjHmnEt1zjUj1Bs/x8wyrps8HJjrnPviyK2zaI7LoTxHSr+IiECevvwi40TJXOr9amZzCKVNVpjZIOAE4LYM1RKBhAz7NQgtgJhIqLeesXxObvdUT11EhHwd/XKCmZX3PscBrYE1ZnYL0Bbo6c3jOWIKcIM3CuY8YK9zbiswE2hjZhW8F6RtvLIcqacuIkK+Tj6qBozx8uoBYKJzbqqZpRBaD2u+d69JzrnBwDSgA7Ae+B24CcA5t9vM/gks8q47+MhL05woqIuIkK+jX5YBp2dRnmW89Ua9ZLkoj3NuNJCnxZsU1EVE0DIBIiK+4pOYrqAuIgL+WftFQV1EBKVfRER8xScxXUFdRATUUxcR8RWfxHQFdRER0ItSERFfUfpFRMRHFNRFRHzEJzFdQV1EBNRTFxHxFZ/EdAV1ERHQ6BcREV8J+KSrrqAuIoLSLyIivqIXpSIiPuKTlLqCuogI6EWpiIivGArqIiK+4ZOOuoK6iAjoRamIiK/4JKYrqIuIgCYfiYj4ika/iIj4iE866grqIiLwF0i/mNmHgMvuuHOuY4G0SEQkAvwR0nPuqT9XaK0QEYkw3w9pdM59XpgNERGJJJ+8JyWQWwUzq29m75rZKjP78chWGI0TESksgYCFveXEzBLMbLaZrTazlWZ271HH/8/MnJlV9vbNzF4ys/VmtszMzshQt7eZrfO23uE8RzgvSt8ABgEvAC2Bm/BP+klEBMjX9EsK8IBzbqmZlQGWmNknzrlVZpYAXAZszlC/PVDf284FXgXONbOKhGLvWYTeby4xsynOuT053TzXnjoQ55z7FDDn3Cbn3GNAq7w9o4hIdAtY+FtOnHNbnXNLvc/7gNVAde/wC8BDZB6E0gkY60K+BsqbWTWgLfCJc263F8g/Adrl9hzh9NQPmlkAWGdm/YCfgCphnCciUmQUxItSM6sFnA4sMLOOwE/Oue+Ould1YEuG/USvLLvyHIXTU78PKAncA5wJXA+EldsRESkqLC+bWV8zW5xh63vM9cxKA+8RiqEpwEDg0WxufTSXQ3mOcu2pO+cWeR/3E8qni4j4Tkwehr8450YCI7M7bmbFCAX0d5xzk8zsFKA2cKSXXgNYambnEOqBJ2Q4vQbws1d+yVHlc3JrW65B3cxmk8VPB+ec8uoi4hv5lX6x0IVeB1Y754YCOOeWkyFtbWYbgbOcc7+Y2RSgn5mNJ/SidK9zbquZzQSeNLMK3mltgAG53T+cnPr/ZfhcAuhC6FcJERHfyMeUenNCaerlZvatV/aIc25aNvWnAR2A9cDveBkR59xuM/sncCRbMtg5tzu3m4eTfllyVNE8M9PEJBHxlfxa+8U59yW5DPt2ztXK8NkBd2VTbzQwOi/3Dyf9UjHDboDQy9KqebmJiEi088kqAWGlX5bwx5vYFGAD0KcgGwVA5YTc64iI5BPfr/2SwcnOuYMZC8yseAG1R0QkImJ8EtTDGaf+VRZl8/O7ISIikZRfM0ojLaf11KsSmr0UZ2an80fivyyhyUgiIr4R7cE6XDmlX9oCNxIa8P48fwT134BHCrZZIiKFy/c5defcGGCMmXVxzr1XiG0SESl0fumph5NTP9PMyh/ZMbMKZvZEAbZJRKTQmYW/RbNwgnp759yvR3a8JSA7FFyTREQKX9As7C2ahTOkMcbMijvnDgGYWRygIY0i4itRHqvDFk5Qfxv41Mze8PZvAsYUXJNERApffi0TEGnhrP3yLzNbBrQmNAJmBlCzoBsmIlKYfBLTw+qpA2wD0oDuhJYJ0GgYEfEVv4x+yWnyUQOgB9AT2AVMIPQ9pS0LqW0iIoUmL1+SEc1y6qmvAb4ArnTOrQcws/sLpVUiIoXMJzE9xyGNXQilXWab2Sgzu5Rc1ggWESmqLA9/olm2Qd05N9k5dw3QiND34t0PxJvZq2bWppDaJyJSKPyyoFeuk4+ccwecc+84564gtA7Mt8DDBd4yEZFC9JcJ6hk553Y750boS6dFxG/MLOwtmoU7pFFExNdi8tTFjV4K6iIi/IVmlIqI/BVEe648XArqIiL89ZYJEBHxtUCUjz8Pl4K6iAjqqYuI+ErQJ0l1BXUREdRTFxHxFQ1pFBHxEZ/EdAV1ERHI45opUcwvzyEiclwCZmFvuTGz0Wa2w8xWHFV+t5mtNbOVZvavDOUDzGy9d6xthvJ2Xtl6MwtrIUX11EVEyPec+pvAK8DYIwVm1hLoBJzqnDtkZlW88saEvmWuCXAiMMv75jmAYcBlQCKwyMymOOdW5XRjBXUREfL3G4Ccc3PNrNZRxXcATzvnDnl1dnjlnYDxXvkGM1sPnOMdW++c+xHAzMZ7dXMM6kq/iIgQelEa7vYnNQBamNkCM/vczM72yqsDWzLUS/TKsivPkXrqIiKQp3XSzawv0DdD0Ujn3MhcTgsCFYDzgLOBiWZWh6x/SXBk3el2ubVNQV1EhLylLbwAnlsQP1oiMMk554CFZpYGVPbKEzLUqwH87H3OrjxbSr+IiJC/o1+y8T7QCsB7ERoL/AJMAXqYWXEzqw3UBxYCi4D6ZlbbzGIJvUydkttN1FMXESFv6ZcwrjUOuASobGaJwCBgNDDaG+Z4GOjt9dpXmtlEQi9AU4C7nHOp3nX6ATOBGGC0c25lbvdWUBcRIX/TFs65ntkcui6b+kOAIVmUTwOm5eXeCuoiIuRvTz2SFNRFRMjfceqRpKAuIgLEqKcuIuIfPonpCuoiIgDmkwSMgrqICOqpi4j4SkA9dTlegYAxb1hvfv5lH13+8R63dzqDfp3Pom71CtTo8hK7fktKr9vi1ASevfNSisXEsOu332nzwDiKF4th1tBexBYLEowJMPmLtTwx9ssIPpEUpPaXtaJkqVLEBALEBGMYN3ESDz5wH5s2bABg3759lClThomTPohwS4sm9dTluPXrfBZrN++iTMlYAOavSGTa1+v5+LlemeqVK1WcF+9pQ6cBE9mycx8nlC8JwKHkVNo9OJ4DB5MJxgT47IVr+XjRjyxcnevyEFJE/eeNMVSoUDF9/9nn/53++bl/PU3p0qUj0Sxf8Mt3lGrtlwipXrkM7c6twxvTv0sv++6HHWze/tsxda9p1ZgPvvyeLTv3AbDz19/Tjx04mAxAsWCAYDBAaNax/NU45/h45nTaX35FpJtSZAUs/C2aqaceIc/ecSkDR82hdFxsrnXr16hIMBhg5nM9KR0Xy7DJi/nvrNASEIGA8dXw3tQ9sQIjpixl0ZqtBd10iRSD22/tg5nRtds1dO1+TfqhpUsWU6lSJWrWrBW59hVxGv0if1r7c+uy49cDfLNuOy1OTci1fjDGOKN+Vdo/NJ642CBzXrqOhat/Zv1Pe0hLc5x3+5uUK1WcCY91pnGtyqza+EshPIUUtjFvj6NKlXh27drF7bfcRO06dTjzrND3LEyfNpV2HdRLPx4+yb4o/RIJ5zepzhXn12fNW7czdmBHLmlWk9H9s/8H+dPOfXy86Ed+P5jMrt+S+HJZIqfWrZKpzt4Dh5j73RbanFWnoJsvEVKlSjwAlSpVolXry1ixfBkAKSkpfDrrE9q16xDJ5hV5loc/0UxBPQIeHT2Xer2G0+j617hhyBTmfLuJm5+Zmm39D+evp/kpNYgJGHHFg5zdqBprNu+icrk4ypUqDkCJ2CCtzqjJ2i27CusxpBD9/vvvHDiwP/3z/K/mUa9efQAWzP+K2rXrEF+1aiSbWOQppy757s6rzuRv3c8lvmIpFo28iRkLf+TOoTNYu3kXnyzawKKRN5OW5nhz+jJWbfyFprVPYNRDlxMTCC3c/97cNUxf8EOkH0MKwO5du7j/nrsASElNpcPlV9C8xUUAzJg+jXYdLo9k83zBL6NfrLBHS5jZTc65N3KrF3fZMxrGIcfYM71/pJsgUahE8PhzIvPW7Qk75jSvXyFqfwJEIv3yeHYHzKyvmS02s8UpiQsKs00i8hdXCF9nVygKJP1iZsuyOwTEZ3dexi9z9VNP/eiZo7OG9qK0N+GoSvmSLF6zle6PTT7mvP0zHmTFxp0AbNnxG90enQRAzarleOuRjlQoW4Jv123n5memkpySxh2dzqDP5c3YsvM3ug+aRHJKGhc0qU6nCxvSf8RnhffAkifzvpjLM08PIS01jc5dutHn1r7H1Jk5YxqvDXsFzGjYsBFPP/s8AKefcjL16zcAoGq1arw07DUABjz0AOvWfc9FF7fknvv+BsCIV4fRoGFDWrZqXUhPVrREd6gOX0Hl1OOBtsCeo8oN+KqA7hm1jp452vpv/00/Nu7Rq/jwq3VZnpd0OIXzbn/zmPIht1zCy5MW8785q3np3jbc2O5URk39lhvbn8bZt41m0I0tuOys2kz7+gcevq45NwzRtPFolZqaypNDBjNi1BvEx8fT65quXNKyFXXr1Uuvs2nTRl4fNZIxb4+jbLly7Nr1x8vw4sVLHLMswPdr1wDw7uQPufH6Xuzbt4+DB5NYsXw5t91xV+E8WFHkk6heUOmXqUBp59ymo7aNwJwCumdUymrm6BGl42K5uFnNbIN6di5udhKT5ob+4b7z8QqubN4g/VixYAwlixcjOSWNXq2bMHPhD/y6/9DxPYQUmBXLl5GQUJMaCQkUi42lXYfLmTP700x1Jv1vIj16XkvZcuWA0JDGnASDxTh46BBpaWkkJycTEwgw/OWXuPPuewrsOfzAL+mXAgnqzrk+zrksV5ZyzvXKqtyvjswcTUs7NpvUsXl95nyziX2/H87y3BKxQb4cdgOfv3Q9V14QGr5WqWwce/cfItW73k+/7OPESqH1Pv797kI+f+l6KpcryfyVP3Fdm6aMmPJNAT2Z5Icd27dTtdofQxGrxMezffv2THU2bdrIpo0b6H1tD67r2Z15X8xNP3b48CF6dr+a63p257NPZwFQp25dqlWtRo+unWnTrj2bN2/G4Tj55MaF81BFlOVhi2Ya0liAcps52r1lY97Mogd/RINrX2Xrrv3UqlqOGc/2ZMWGnez7/dhe95EfF+NmrWSct3zAI9c1Z/jkJbQ9pw7Xtm5K4s7f6D/iM7Q0THRxHPs/5OgvQE5JTWXT5k3858232L59GzfdcC3vvT+VsmXLMmPWbKpUiSdxyxZuvbk39es3IOGkk3howMD08+++83b+8djjjBrxKt+vXcN55zenS7fuBf5sRU60R+swafJRAcpp5mjFMiU4q1G1HMeVb90Vmmyycdte5i7bTLN68fyyN4lypYsT482AqF65THq9I6pVKs2ZDasydf56Hu51PtcN+YBDyam0PL1WwTyo/Gnx8VXZtnVb+v6O7dupUqXKUXXiadnyUooVK0aNGgnUqlWbzZs2An/MMq2RkMBZZ5/DmtWrMp07+7NZNGnalKSkJNavW8ezQ19k6ocfkJSUhGSmGaWSq5xmjl59cSOmf72eQ8mpWZ5bvnRxYovFAKGUy/lNqrN6U2hNl7nfbebqixoBcG2bpkw9Kif/aO8WDH7zCwBKFC+Gc4405yhZXL+YRZsmTU9h8+aNJCZuIfnwYWZM+4iLW7bKVKdVq9YsWhga4rtnz242bdpIjYQEftu7l8OHD6eXf/vNUurU/eMFa3JyMu+8NZbeN/XhYNLB9N8AjuTaJTOz8Ldopn/lEdLtkpN5bvzXmcrOaFCVW65oxp1DZ9DopMq8fF9b0tIcgYDx3PgFrNkcGvUwcNQc3hrYkUE3tuC7H7bz5ow/RpCe5q0J890POwAYM30Zi0f2IXHnbwx5a14hPZ2EKxgMMmDgo9zR9xbS0lK5qnMX6tWrz7CXX6RJk6Zc0upSLriwBV99NY/OV3YgEBPD/Q88RPnyFfj2m6X88/FBBMxIc46bbrk106iZCePeoWOnzsTFxdGgYUOcc3S56koubHERZcuWjeBTR6coj9VhK/QZpeHy0zh1yT+aUSpZyY8Zpd9s2hd2zDm9Zpmo/RmgnrqICNGfVgmXgrqICP5Jvyioi4iAb6K6grqICP75OjsNaRQRIX+HNJrZ/Wa20sxWmNk4MythZrXNbIGZrTOzCWbZGImrAAAFyElEQVQW69Ut7u2v947XOp7nUFAXESH/grqZVQfuAc5yzjUFYoAewDPAC865+oQWO+zjndIH2OOcqwe84NX70xTURUTI9xmlQSDOzIJASWAr0Ap41zs+BrjK+9zJ28c7fqkdvVZEHiioi4iQfz1159xPwHPAZkLBfC+wBPjVOZfiVUsEqnufqwNbvHNTvPo5L8WZAwV1ERHytkpjxm9p87b0bzYxswqEet+1gROBUkD7LG55ZLJTVj8m/vTkS41+ERGBPA1pzPgtbVloDWxwzu0EMLNJwAVAeTMLer3xGsDPXv1EIAFI9NI15YDdf+YRQD11EREgX78kYzNwnpmV9HLjlwKrgNlAV69Ob+DIV1ZN8fbxjn/mjmP9FvXURUTIv7lHzrkFZvYusBRIAb4h1Kv/CBhvZk94Za97p7wOvGVm6wn10Hscz/0V1EVEIF9nlDrnBgGDjir+ETgni7oHgW75dW8FdRER/DOjVEFdRASt0igi4is+iekK6iIicOwXfhdVCuoiIij9IiLiKz6J6QrqIiKAb6K6grqICBrSKCLiK8qpi4j4SEBBXUTET/wR1RXURURQ+kVExFd8EtMV1EVEQD11ERFf0TIBIiI+4o+QrqAuIgIo/SIi4iuaUSoi4if+iOkK6iIi4JuYrqAuIgIQ8ElSXUFdRAT/vCgNRLoBIiKSf9RTFxHBPz11BXURETSkUUTEV9RTFxHxEQV1EREfUfpFRMRH1FMXEfERn8R0BXUREcA3UV1BXUQE/ywTYM65SLdBcmFmfZ1zIyPdDoku+nshWdEyAUVD30g3QKKS/l7IMRTURUR8REFdRMRHFNSLBuVNJSv6eyHH0ItSEREfUU9dRMRHFNSjnJm1M7O1ZrbezB6OdHsk8sxstJntMLMVkW6LRB8F9ShmZjHAMKA90BjoaWaNI9sqiQJvAu0i3QiJTgrq0e0cYL1z7kfn3GFgPNApwm2SCHPOzQV2R7odEp0U1KNbdWBLhv1Er0xEJEsK6tEtq8UoNFxJRLKloB7dEoGEDPs1gJ8j1BYRKQIU1KPbIqC+mdU2s1igBzAlwm0SkSimoB7FnHMpQD9gJrAamOicWxnZVkmkmdk4YD7Q0MwSzaxPpNsk0UMzSkVEfEQ9dRERH1FQFxHxEQV1EREfUVAXEfERBXURER9RUJd8Z2apZvatma0ws/+ZWcnjuNYlZjbV+9wxp5Uqzay8md35J+7xmJn9359to0g0UVCXgpDknGvmnGsKHAZuz3jQQvL8d885N8U593QOVcoDeQ7qIn6ioC4F7QugnpnVMrPVZjYcWAokmFkbM5tvZku9Hn1pSF9Dfo2ZfQlcfeRCZnajmb3ifY43s8lm9p23XQA8DdT1fkt41qv3oJktMrNlZvZ4hmsN9NapnwU0LLT/GiIFTEFdCoyZBQmtBb/cK2oIjHXOnQ4cAP4OtHbOnQEsBv5mZiWAUcCVQAugajaXfwn43Dl3GnAGsBJ4GPjB+y3hQTNrA9QntIRxM+BMM7vIzM4ktOTC6YR+aJydz48uEjHBSDdAfCnOzL71Pn8BvA6cCGxyzn3tlZ9H6Is/5pkZQCyhqe+NgA3OuXUAZvY20DeLe7QCbgBwzqUCe82swlF12njbN95+aUJBvgww2Tn3u3cPracjvqGgLgUhyTnXLGOBF7gPZCwCPnHO9TyqXjPyb3lhA55yzo046h735eM9RKKK0i8SKV8Dzc2sHoCZlTSzBsAaoLaZ1fXq9czm/E+BO7xzY8ysLLCPUC/8iJnAzRly9dXNrAowF+hsZnFmVoZQqkfEFxTUJSKcczuBG4FxZraMUJBv5Jw7SCjd8pH3onRTNpe4F2hpZsuBJUAT59wuQumcFWb2rHPuY+C/wHyv3rtAGefcUmAC8C3wHqEUkYgvaJVGEREfUU9dRMRHFNRFRHxEQV1ExEcU1EVEfERBXUTERxTURUR8REFdRMRHFNRFRHzk/wH0BgnXcBHmRQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm(y_test, preds6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.99      0.68      4545\n",
      "           1       0.55      0.01      0.03      4220\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      8765\n",
      "   macro avg       0.54      0.50      0.35      8765\n",
      "weighted avg       0.54      0.52      0.37      8765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model4 = svm.SVC(cache_size=3500, C=.5, gamma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.5, cache_size=3500, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.5, cache_size=3500, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds7 = svm_model4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix test: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm(y_test, preds7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.68      4545\n",
      "           1       0.00      0.00      0.00      4220\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      8765\n",
      "   macro avg       0.26      0.50      0.34      8765\n",
      "weighted avg       0.27      0.52      0.35      8765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was not able to get any good results with the modeling methods used, though I did not do a proper EDA or really go into this data much.  \n",
    "This demonstration is more to show the possibilities behind putting the gridsearch results into a dataframe so you can better decide which parameters you would choose, instead of just taking what the girdsearch says is it's best parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
